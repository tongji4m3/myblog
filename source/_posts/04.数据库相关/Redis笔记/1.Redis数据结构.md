---
title: Redis数据结构
author: tongji4m3
top: true
cover: false
coverImg: /images/1.jpg
toc: true
mathjax: false
summary: 学习Redis所做的笔记，此为Redis数据结构，包括底层数据结构、布隆过滤器等。
categories: Redis
tags:
  - Redis
  - 数据结构
  - 布隆过滤器
abbrlink: 85682d75
date: 2020-11-11 00:00:00
---



# Redis简介

它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。

命令不区分大小写，而key区分大小写

Redis所有的数据结构都以唯一的key字符串作为名称，不同类型的数据结构的差异就在于value的结构不一样

所有数据结构都可以设置过期时间

# 底层数据结构

## 简单动态字符串

### SDS简介

+ 使用**简单动态字符串**(simple dynamic string SDS)作为默认字符串
+ c字符串只作为字符串字面量，用在无需对字符串值进行修改的地方
+ 包含字符串值的键值对在底层都是用SDS实现的

### SDS的定义

```c
struct sdshdr
{
	int len;//记录buf数组中已使用字节的数量 为字符串长度
	int free;//未使用的数量
	char buf[];//字节数组，用来保存字符串
}
```

1. buf数组以空字符结尾，且最后的空字符不算在len里面
2. 该空字符由SDS函数自动完成，对SDS用户透明

### SDS与C字符串的区别

#### 获取字符串长度所需复杂度从O(N)降低到​O(1)​

#### 杜绝了缓冲区溢出

例如c进行字符串拼接，需要假设已经为字符串分配了足够的内存以容纳要拼接的字符串，否则就会溢出。
**SDS空间分配策略**完全杜绝了发生缓冲区溢出的可能性。当要对SDS进行修改时，会先检查空间是否满足修改所需的要求，如果不满足，则会自动将**SDS的空间扩展**，然后再执行实际的修改操作

#### 减少修改字符串时带来的内存重分配次数

C字符串底层实现总是一个N+1个字符长的数组，每次对该数组进行增加或缩短，总要进行一次**内存重分配**操作。如果是增长，则要内存重分配扩展底层数组的空间大小。如果是缩短，则执行操作后，需要内存重分配来释放空间，避免内存泄漏。

Redis通过**未使用空间**解除了字符串长度和底层数组长度之间的关联

##### 空间预分配

用于优化SDS的字符串增长操作，在扩展SDS空间之前，会先检查未使用的空间是否足够，如果足够，则直接使用未使用空间，无需进行内存重分配。

在对一个SDS进行修改，并且需要对SDS进行空间扩展时，不仅为SDS分配修改所需要的空间，还会分配额外的未使用空间。

如果修改后 SDS.len < 1MB，程序会分配给和len一样的长度给free

如果修改后 SDS.len >= 1MB，程序会分配1MB给free

##### 惰性空间释放

用于优化SDS字符串缩短操作：不立即回收缩短后多出来的字节，而是用free记录。避免了缩短字符串时所需的内存重分配操作，并且为将来可能的增长提供了优化

API也让我们在需要时，真正释放SDS的未使用空间，不用担心惰性空间释放策略会造成内存浪费

#### 二进制安全

1. C字符串并且符合特定的编码，并且除字符串的末尾外，不能包含空字符，使得他只能保存文本数据
2. Redis以处理二进制的方式处理SDS存放在buf数组的数据，使用len而不是空字符判断字符串是否结束。所以他可以保存**任意格式**的二进制数据。

#### 兼容部分C字符串函数

SDS保存数据的末尾总是为空字符，所以让那些保存文本数据的SDS可以重用一部分<string.h>库'定义的函数

## 链表

被广泛用于实现Redis的各种功能，如列表键，发布与订阅，慢查询，监视器等等

### 链表和链表节点的实现

```c
typedef struct listNode
{
	struct listNode * prev;
	struct listNode * next;
	void * value;
}listNode;
```

```c
typedef struct list
{
	listNode *head;
	listNode *tail;
	unsigned long len;
	
	void *(*dup)(void *ptr);//节点值的复制函数
	void (*free)(void * ptr);//节点值的释放函数
	int (*match)(void * ptr，void * key);//节点值的对比函数
}
```

### 特性总结

+ 双端、无环、带表头和表尾指针、带链表长度计数器
+ 多态：可以保存各种不同类型的值



## 字典

Redis的数据库底层就是用字典实现的

字典也是**哈希键**的底层实现之一

### 字典的实现

字典采用哈希表作为底层实现，一个哈希表可以有多个哈希表节点，每个节点保存了一个键值对

每个字典带有**两个哈希表**，一个平时使用，一个仅仅在rehash时使用

### 哈希表

```c
typedef struct dictht
{
	dictEntry ** table;//哈希表数组
	unsigned long size;
	unsigned long sizemask;//哈希表大小掩码，用于计算索引值 总=size-1
	unsigned long used;
}dictht;
```

sizemask和哈希值一起决定一个键应该放到table数组里面的哪个索引上

### 哈希表节点

```c
typedef struct dictEntry
{
	void *key;
	union
	{
		void *val;
		uint64_t u64;
		int64_t s64;
	} v;
	struct dictEntry * next; 
}dictEntry;
```

值可以是应该指针，或者是应该uint64_t类型的整数，或是一个int64_t整数

next属性指向另一个哈希表节点的指针，可以将多个哈希值相同的键值对连接在一起，以解决键冲突

### 字典

```c
typedef struct dict
{
	dicType * type;//类型特定函数
	void * privdata;//私有数据
	ditcht ht[2];//哈希表
	
	int rehashidx;//rehash索引，当rehash不再进行时，值为-1
}dict;
```

1. type，privdata属性是针对不同类型的键值对，为创建多态字典而设置的
2. 每个dicType结构保存了一簇用于操作特定类型键值对的函数
3. privdata属性保存了需要传给那些类型特定函数的可选参数
4. ht数组中，每个项都是**ditcht哈希表**，一般只使用ht[0]，ht[1]只会在ht[0]进行rehash时使用
5. rehashidx记录rehash目前的进度

### 哈希算法

程序先通过键计算哈希值hash，在计算索引(hash & sizemask)，再根据索引将包含新键值对的哈希表节点放到哈希表数组的指定索引上

### 解决键冲突

用链地址法，多个分配到同一个索引的节点用单向链表连接起来。且用**头插法**，将新节点添加到链表的表头位置 

### rehash

#### 时机

1. 若没有在执行BGSAVE或BGREWRITEAOF命令，则哈希表负载因子大于等于1时rehash
2. 若在执行BGSAVE或BGREWRITEAOF命令，则哈希表负载因子大于等于5时rehash
3. load_factor=ht[0].used / ht[0].size
4. 以上的不同是因为，执行那两个命令时，Redis需要创建当前服务器进程的**子进程**，在子进程存在期间，服务器会提高执行扩展操作所需的负载因子，从而京可能避免在子进程存在期间进行哈希表的扩展操作，可以避免不必要的内存写入操作，最大限度地节约内存
5. 当负载因子小于0.1，则自动进行收缩操作

#### 步骤

1. 为字典的ht[1]哈希表分配空间
    - 如果是扩展，则ht[1]大小为第一个大于等于 ht[0].used * 2 的2^n​。
    - 如果是收缩，则是第一个大于等于 ht[0].used 的2^n​。
2. 将保存在ht[0]的所有键值对rehash到ht[1]上面，即重新计算哈希值和索引值，然后放到ht[1]的指定位置上
3. 当ht[0]所有的键值对都迁移到了ht[1]，则将ht[1]设置为ht[0]，并且在ht[1]新建一个空哈希表

### 渐进式rehash

1. rehash时，服务器不是一次就将ht[0]里面的所有键值对全部rehash到ht[1]。而是分多次，**渐进式**地将ht[0]里面的键值对慢慢地rehash到ht[1]
2. 在执行操作之外，顺带将键值对rehash到ht[1]中，把rehash键值对所需的计算工作均摊到每次对字典的增删改查操作之中。当rehash工作完成后，将rehashidx属性的值加一。所有的键rehash完毕后，rehashidx设置为-1
3. 在进行渐进式rehash时，字典**同时**使用ht[0]，ht[1]。所以操作同时在两个哈希表中进行，即如果要查找一个键，会先在ht[0]找，没找到就继续到ht[1]中找
4. 新添加的键值对直接保存到ht[1]中



## 跳跃表

+ 通过在每个节点中维持多个指向其他节点的指针，从而快速访问节点
+ 查找速度:平均O(log N)，最坏O(N)
+ 支持顺序性操作
+ 使用跳跃表作为有序集合键的底层实现之一

- 因为要进行随机的插入和删除，不便用数组

- 要定位插入位置一般用二分查找

- 层级制，最下面所有元素串起来，每隔几个元素挑选一个代表，再将这几个代表用另外一级指针串起来，然后继续选出二级代表，最后形成金字塔结构

- 插入，先在顶层定位，然后下潜到下一级定位，一直下潜到最底层找到合适的位置，将新元素插入进去

- 随机策略，位于L0层概率为1，兼职L1层概率0.5，到L2层0.25，概率逐层降低


### 性质

1. 每一层都是一个有序的链表，最底层(L1)的链表包含**所有元素**
2. 如果一个元素出现在第 n 层的链表中，则它也出现在第 n-1 层
3. 搜索先从上层搜索，当前面的元素比target大时，则向下一级搜索(即向着更密集的数据找)
4. 总体来看从左上往右下寻找

### 查找代码

从每个节点的最高层开始寻找，如果该层forward不为null，并且分值小于score，则跳到下一个节点，即x = x->level[i].forward，然后如果相等，则返回。如果该层的forward不满足，则遍历自己的下一个层级(level[i-1])的位置。综上就是从左往右，从上往下。

```c
// 通过分值和对象值获取排位信息，以1为起始值
unsigned long zslGetRank(zskiplist *zsl， double score， robj *o) {
    zskiplistNode *x;
    unsigned long rank = 0;
    int i;

    x = zsl->header;
    // 从最高层依次往下
    for (i = zsl->level-1; i >= 0; i--) {
        while (x->level[i].forward &&
            (x->level[i].forward->score < score ||
                (x->level[i].forward->score == score &&
                compareStringObjects(x->level[i].forward->obj，o) <= 0))) {
            // 排位增加
            rank += x->level[i].span;
            x = x->level[i].forward;
        }

        /* x might be equal to zsl->header， so test if obj is non-NULL */
        // 对象和分数值都相等
        if (x->obj && equalStringObjects(x->obj，o)) {
            return rank;
        }
    }
    return 0;
}
```

### 原理

![IMG_20200818_102630](https://tongji4m3.oss-cn-beijing.aliyuncs.com/IMG_20200818_102630.jpg)

level:表中层数最大的节点的层数

length:节点数量

### 跳跃表节点

```c
typedef struct zskiplistNode
{
	struct zskiplistNode * backward;//后退指针
	double score;//分值
	robj * obj;//成员对象
	
	struct zskiplistLevel //层
	{
		struct zskiplistNode * forward; //前进指针
		unsigned int span;//跨度
	}
}
```

#### 层

level数组可以包含多个元素，每个元素都包含一个指向其他节点的指针，来加快访问其他节点的速度

感觉幂次规律，随机生成一个[1，32]的值作为level数组的大小，即层的高度

#### 前进指针

每个层都有一个指向表尾方向的前进指针(level[i].forward)

#### 跨度

记录两个节点之间的距离

指向NULL的所有前进指针的跨度都为0

跨度实际是用来计算排位的:在查找某个节点过程中，将沿途访问的所有层的跨度累积起来，得到的结果就是目标节点在跳跃表中的排位(即该节点是第几个节点)

#### 后退指针

可以先通过跳跃表的tail指针访问表尾节点，然后通过后退指针访问倒数第二个节点...，直到遇到指向NULL的后退指针

#### 分值和成员

1. 分值:跳跃表中所有节点都按分值从小到大排序
2. 成员对象:指向**SDS字符串**对象的指针
3. 跳跃表中成员对象必须唯一，但是分值可以相同
4. 分值相同的节点按照成员变量的字典序排序

### 跳跃表结构

```c
typedef struct zskiplist
{
	struct zskiplistNode * header，*tial;
	unsigned long length;//表中节点的数量
	int level;//表中层数最大的节点的层数
} zskiplist;
```

使得能O(1)访问表头表尾节点，访问跳跃表长度，获取表中层数最大的节点的层数

## 整数集合

当一个集合只包含整数值元素，并且数量不多时，redis就会采用整数集合作为集合键的底层实现

```c
typedef strcut intset
{
	uint32_t encoding; //编码方式
	uint32_t length; //元素数量
	int8_t contents[]; //保存元素的数组
}
```

可以保存类型为 int16_t，int32_t，int64_t的**非重复**整数值，且元素在contents数组中**有序排列**

### 升级

每当添加一个新元素到整数集合里面，并且新元素的类型比**现有所有元素类型**都长，需要先对整数集合进行升级，再加入该元素

1. 根据新元素类型，扩展整数集合底层数组的空间大小，并为新元素分配空间
2. 将底层数组现有的**所有元素转换**成与新元素相同的类型，并且放置到正确位置上，仍需**保证有序性**
3. 将新元素添加到底层数组里

每次添加新元素都有可能引起升级，而每次升级都需要对底层数组所有元素进行类型转换，所以添加新元素时间复杂度为O(N)

### 升级的好处

#### 提升灵活性

整数集合可以通过自动升级底层数组来适应新元素，所以可以将 int16_t、int32_t、int64_t随意地添加到集合中，不必担心类型错误

#### 节约内存

既可以让集合能**同时保存三种不同类型**的值，又可以确保升级只在必要时进行

### 降级

**不支持**降级操作，即使把之前因为他而升级的元素删除，底层数组还仍然是加入那个元素后的类型



## 压缩列表

- 压缩列表是列表键和哈希键的底层实现之一
- 当一个列表键只包含**少量列表项**，并且每个列表项都是**小整数或较短字符串**，则用压缩列表作为底层实现
- 压缩列表是为了**节约内存**而开发的，是由一系列特殊编码的连续内存块组成的**顺序型数据结构**
    - zlbytes：记录整个压缩列表所占用的内存字节数，在内存重分配或zlend位置时使用
    - zltail：记录压缩列表表尾节点距压缩列表的起始地址有多少字节，通过该偏移量，可无须遍历整个压缩列表就可以确定表尾节点的地址
    - zllen：记录了压缩列表包含的节点数量
    - entryX：压缩列表包含的各个节点，节点长度由节点包含的内容决定
    - zlend：特殊值0xFF，用于标记压缩列表的末端

![image-20210207091430874](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207091430874.png)

### 压缩列表节点的构成

![image-20210207091652786](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207091652786.png)

#### previous_entry_length

- 记录压缩列表**前一个节点**的长度
- 通过指针运算，根据当前节点的起始地址得到前一个节点的起始地址
- 用于从表尾到表头的遍历：指向表尾节点的指针可以通过压缩列表的起始地址的指针加上zltail得到

#### encoding

记录节点的content属性所保存数据的类型及长度

#### content

负责保存节点的值，值的类型和属性由encoding决定

### 连锁更新

- 每个节点的previous_entry_length属性都记录了前一个节点的长度，如果前一节点长度小于254字节，则previous_entry_length属性用1字节空间保存该长度值，否则需要用5字节空间。
- 如果在压缩列表中，有多个介于[250，153]字节的节点[e1，eN]，记录这些节点的长度只需要1字节长的**previous_entry_length**，所以[e1，eN]所有节点的**previous_entry_length**都是1字节长

- 但如果将一个大于254字节的新节点new加入压缩列表的头节点，则new成为e1的前置节点。而这样e1的**previous_entry_length**属性不足以保存new的长度，所以进行空间重分配，变成5字节大小

- 这样e1的长度大于254字节了，e2的**previous_entry_length**也不足以保存e1的长度，也扩展成5字节大小。这样就进行连续多次空间扩展，即连锁更新

- 删除节点也会引发连锁更新
- 连锁更新在最坏情况下需要对压缩列表进行N次空间重分配操作，每次操作最坏O(N)，所以连锁更新最坏时间复杂度为O(N^2)​.
- 但是发生的机率比较低：
    - 恰好有多个连续的，长度介于250-153字节的节点的情况并不多见 
    - 即使出现连锁更新，只要被更新的节点数量不多，就不会对性能有影响
- 所以平均复杂度为O(N)



# 基础数据结构

每个键值对都是由对象组成，键总是一个字符串对象，值可以是五种对象中的一种

如果容器不存在，则先创建一个再进行操作

如果容器里元素为空，则立刻删除容器，释放内存

## string

+ 点赞数量:  incr likes 每操作一  次，就+1，最后可以通过get likes得到最终结果
+ 将用户信息使用JSON序列化为字符串，将字符串塞进Redis来缓存
+ 如果value是整数，则可以进行自增操作。用于计数器：可以快速实现计数和查询的功能。

## list

+ 相当于LinkedList，是链表不是数组，插入删除快，索引定位慢
+ 元素较少时会使用一块连续内存存储，即ziplist（压缩列表），所有元素彼此紧挨着一起存储
+ 元素较多时采用快速链表（quicklist），将多个ziplist使用双向指针串起来使用，既满足快速插入删除，又不会出现太大空间冗余

### 应用场景

+ 粉丝列表、文章的评论列表

+ 通过 lrange 命令，读取某个闭区间内的元素，可以基于 List 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。

+ 消息队列（异步队列）：数据的生产者可以通过Lpush命令从左边插入数据，多个数据消费者，可以使用BRpop命令阻塞的“抢”列表尾部的数据。

    

## hash

- 类似与Map<String，Map<String，String>

- 和HashMap一样采用数组+链表

- Redis字典的值只能是字符串

- 渐进式rehash策略：在rehash时保留新旧两个hash结构，查询时会同时查询两个hash结构，循序渐进的将旧hash的内容一点点地迁移到新的hash结构中

- 记录帖子的点赞数、评论数、点击数

    


## set

- 相当于HashSet，键值对是无序的、唯一的。相当于所有value都是NULL的hash

- 统计中奖的用户ID，可以去重


+ 交集运算:微博共同关注 SINTER key1 key2
+ 朋友圈点赞
+ 抽奖活动
	+ SADD key 添加参与
	+ SCARD key 查看有几个人参与了抽奖
	+ SRANDMEMBER key 2 随机抽两个人，不删除
	+ SPOP key 随机抽取并删除1个人

## zset

+ 类似于SortedSet和HashMap的结合体，保证了value的唯一性，每个value有score（排序权重）

+ 热搜

+ 游戏排名

+ 排行榜：榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。

+ 微博热搜榜，value是名称，score是热度值

+ 粉丝列表，value是粉丝用户ID，score是关注时间

+ 学生成绩，value是学生ID，score是考试成绩

    



# 位图bitmap

位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组

可以使用get/set 直接获取和设置整个位图的内容，也可以使⽤位图操作 getbit/setbit 等将 byte 数组看成「位数组」来处理。

位数组会自动扩展，如果设置了某个偏移位置超出了现有的内容范围，就会自动进行零扩充



## 应用场景

用户签到

+ 有些bool 型数据需要存取，例如用户⼀年的签到记录，签了是 1，没签是0，要记录 365 天
+ 位图数据结构让每天的签到记录只占据⼀个位，365 天就是 365个位，46 个字节 (⼀个稍长⼀点的字符串) 就可以完全容纳下
+ 统计和查找
    + bitcount：统计指定范围内1的个数，可以统计用户一共签到多少天 
    + bitpos：用于查找指定范围内出现的第一个0或1，从哪天开始第一次签到

# HyperLogLog

+ 提供不精确的去重统计方案，标准误差是0.81%
+ 不能知道一个值是否在结构中，即不提供 pfcontains功能

+ pfadd 和 pfcount，⼀个是增加计数，⼀个是获取计数。pfadd codehole user1（将用户ID塞进去）；pfcount codehole
+ pfmerge：用于将多个pf计数值累加在一起形成一个新的pf值，例如两个差不多的页面进行合并，需要将页面的UV访问量也合并
+ 场景：UV（Unique Visitor） 需要去重，同⼀个用户⼀天之内的多次访问请求只能计数⼀次。
+ 实现：计数较小时使用稀疏矩阵存储，占用空间超过阈值，则转成稠密矩阵

# Bloom Filter

## 定义

布隆过滤器是一个很长的二进制向量和一系列随机映射函数。

优点是空间效率和查询时间都远远超过⼀般的算法

## 原理

当⼀个元素被加⼊集合时，通过K个散列函数将这个元素映射成⼀个位数组中的K 个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（⼤约）知道集合中有没有它了：如 果这些点有任何⼀个0，则被检元素⼀定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。

Bloom Filter跟单哈希函数Bit-Map不同之处在于：Bloom Filter使⽤了k个哈希函数，每个字符串跟k个 bit对应。从⽽降低了冲突的概率。

## 特点

+ 是一个很长的二进制向量和一系列随机映射函数
+ 当⼀个元素被加⼊集合时，通过K个散列函数将这个元素映射成⼀个位数组中的K 个点，把它们置为1
+ exists：把hash的几个位置都算出来，看看位数组在几个位置是否都为1
    + 如果这些点有任何⼀个0，则被检元素⼀定不在
    + 如果都是1，则被检元素很可能在
+ 空间效率和查询时间都远远超过⼀般的算法
+ 存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1
+ 删除困难。⼀个放⼊容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为 0，可能会影响其他元素的判断。

## 缺点

缺点是有⼀定的误识别率和删除困难，bloom filter之所以能做到在时间和空间上的效率⽐较⾼，是因为牺牲了判断的准确率、删除的便利性

+ 存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。如果 bloom filter中存储的是⿊名单，那么可以通过建⽴⼀个⽩名单来存储可能会误判的元素。
+ 删除困难。⼀个放⼊容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为 0，可能会影响其他元素的判断。

## 实现

+ 在使⽤bloom filter时，绕不过的两点是预估数据量n以及期望的误判率fpp
+  在实现bloom filter时，绕不过的两点就是hash函数的选取以及bit数组的⼤⼩。
+ 对于⼀个确定的场景，我们预估要存的数据量为n，期望的误判率为fpp，然后需要计算我们需要的Bit数 组的⼤⼩m，以及hash函数的个数k，并选择hash函数
+ 一个好的哈希函数要能近似等概率的将字符串映射到各个 Bit。选择k个不同的哈希函数⽐较麻烦，⼀种简单的⽅法是选择⼀个哈希函数，然后送⼊k个不同的参数。 

```java
//项目要导入guava的maven依赖
package com.tongji;


import com.google.common.hash.BloomFilter;
import com.google.common.hash.Funnels;

/**
 * 测试布隆过滤器(可用于redis缓存穿透)
 * @author tongji4m3
 */

public class TestBloomFilter {
    private static int total = 1000000;
    /*
    static <T> BloomFilter<T> create(Funnel<? super T> funnel， long expectedInsertions， double fpp， BloomFilter.Strategy strategy)
    funnel：数据类型(⼀般是调⽤Funnels⼯具类中的)
    expectedInsertions：期望插⼊的值的个数
    fpp 错误率(默认值为0.03)
    strategy 哈希算法

    numBits，表示存⼀百万个int类型数字，需要的位数为7298440，700多万位。理论上存⼀百万个
    数，⼀个int是4字节32位，需要481000000=3200万位。如果使⽤HashMap去存，按HashMap50%的
    存储效率，需要6400万位。可以看出BloomFilter的存储空间很⼩，只有HashMap的1/10左右

    错误率越⼤，所需空间和时间越⼩，错误率越⼩，所需空间和时间越⼤
     */
    private static BloomFilter<Integer> bloomFilter = BloomFilter.create(Funnels.integerFunnel()， total);

    public static void main(String[] args) {
        //初始化total条数据到过滤器里
        for (int i = 0; i < total; i++) {
            bloomFilter.put(i);
        }
        //匹配已经再过滤器中的值，看是否有匹配不上的
        //没有输出，说明只要放进去的，都能匹配上
        for (int i = 0; i < total; i++) {
            if (!bloomFilter.mightContain(i)) {
                System.out.println("有坏人逃脱啦~");
            }
        }

        //匹配不在过滤器中的10000个值，有多少匹配出来
        int count = 0;
        for (int i = total; i < total + 10000; i++) {
            if (bloomFilter.mightContain(i)) {
                ++count;
            }
        }
        //误伤数量: 320 错误率是0.03左右
        System.out.println("误伤数量: "+count);
    }
}
```

## 应用

### 缓存击穿

数据库的id都是1开始然后⾃增的，那我知道你接⼝是通过id查询的，我就拿负数去查询，这个时候，会发现缓存⾥⾯没这个数据，我⼜去数据库查也没有，⼀个请求这样，100个，1000 个，10000个呢？你的DB基本上就扛不住了，如果在缓存⾥⾯加上这个，是不是就不存在了，你判断没这个数据就不去查了，直接return⼀个数据为空不就好了嘛。

+ 海量数据去重
+ 用于检索一个元素是否在一个集合中
+ 爬⾍过滤已抓到的url就不再抓，可⽤bloom filter过滤，只会使得爬虫系统错过少量的新页面
+ 垃圾邮件过滤。Bloom Filter只需要哈希表 1/8到 1/4 的大小
+ 海量数据去重：不断放入元素到集合中，检索一个元素是否在一个集合中，在则说明重复、推荐去重，即APP会把用户已经看过的内容去掉、能准确过滤掉用户已经看过的内容，那些用户没有看过的新内容，也会过滤掉极小一部分（误判）

# 地理位置Geo模块

+ 可以用于“附近的人”
+ 使用Geo，则所有都会放在一个zset集合中，可能很大
+ 如果单个key过大，会对集群的迁移造成较大影响
+ 所以建议Geo的数据使用单独的Redis实例部署，不使用集群

## 原理

+ 地理位置距离排序算法：GeoHash
+ 将二维的经纬度数据映射到一维的整数，再在这个一维的线上获取附近的点即可
+ 映射算法类似于切蛋糕法，将地图元素坐标放置于唯一的方格中，并得到一个编号
+ 进行Geo查询时，内部结构是zset，通过zset的score排序就可以得到坐标附近的其他元素，通过将score还原成坐标值可以得到元素的原始坐标

## 命令

+ geoadd 集合名称 {经度 纬度 名称}

+ geodist 集合名称 名称1 名称2 km（单位），计算两个元素之间的距离

+ geopos 集合名称 名称，获取元素经纬度坐标

    