---
title: 数据库——Redis相关笔记------Redis设计机制
author: tongji4m3
top: false
cover: false
coverImg: /images/1.jpg
toc: true
mathjax: false
summary: 学习Redis所做的笔记，此为Redis设计机制，包括IO多路复用模型、LRU等。
categories: Redis
tags:
  - Redis
  - IO多路复用
  - LRU
abbrlink: 103d28f6
date: 2020-11-17 00:00:00
---



# 基本认识

Remote Dictionary Service(远程词典服务)

存储中间件

**Redis**采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的**QPS（每秒内查询次数）**。

- 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。它的，数据存在内存中，类似于**HashMap**，**HashMap**的优势就是查找和操作的时间复杂度都是O(1)；
- 数据结构简单，对数据操作也简单，**Redis**中的数据结构是专门进行设计的；
- 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 **CPU**，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
- 使用多路I/O复用模型，非阻塞IO；
- 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，**Redis**直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

# 单线程

服务器都是多核的，可以通过在单机开多个**Redis实例**解决浪费

# 单机瓶颈

用到了集群的部署方式也就是**Redis cluster**，并且是主从同步读写分离，类似**Mysql**的主从同步，**Redis cluster** 支撑 N 个 **Redis master node**，每个**master node**都可以挂载多个 **slave node**。

这样整个 **Redis** 就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 **master** 节点，每个 **master** 节点就能存放更多的数据了。



# IO模型

![image-20210207165051430](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207165051430.png)

## 分类

- 同步阻塞IO（Blocking IO）：即传统的IO模型。
- 同步非阻塞IO（Non-blocking IO）：默认创建的socket都是阻塞的，非阻塞IO要求socket被设置为NONBLOCK。注意这里所说的NIO并非Java的NIO（New IO）库。
- IO多路复用（IO Multiplexing）：即经典的Reactor设计模式，有时也称为异步阻塞IO，Java中的Selector和Linux中的epoll都是这种模型。
- 异步IO（Asynchronous IO）：即经典的Proactor设计模式，也称为异步非阻塞IO。

**同步和异步**的概念描述的是用户线程与内核的交互方式：同步是指用户线程发起IO请求后需要等待或者轮询内核IO操作完成后才能继续执行；而异步是指用户线程发起IO请求后仍继续执行，当内核IO操作完成后会通知用户线程，或者调用用户线程注册的回调函数。

**阻塞和非阻塞**的概念描述的是用户线程调用内核IO操作的方式：阻塞是指IO操作需要彻底完成后才返回到用户空间；而非阻塞是指IO操作被调用后立即返回给用户一个状态值，无需等到IO操作彻底完成。



同步异步强调结果的返回形式，例如问别人借钱，可能当场给100块钱，也可能犹豫了很久才给100块钱



**I/0 操作主要分成两部分**
① 数据准备，将数据加载到内核缓存（数据加载到操作系统）
② 将内核缓存中的数据加载到用户缓存（从操作系统复制到应用中）

## 传统同步阻塞IO模型

- 同步阻塞IO模型是最简单的IO模型，用户线程在内核进行IO操作时被阻塞。

- 用户线程通过系统调用read发起IO读操作，由用户空间转到内核空间。内核等到数据包到达后，然后将接收的数据拷贝到用户空间，完成read操作。

- 服务端采用单线程，当 accept 一个请求后，在read调用阻塞时，将无法 accept 其他请求（必须等上一个请求处理完 ）（无法处理并发）

- 套接字的读写方法，默认是阻塞的。例如read方法要传递进去一个参数n，代表最多读取n个字节后再返回，如果一个字节都没有，则线程卡顿直到新的数据到来或连接关闭，read方法才能返回。

- write方法一般不会阻塞，除非内核为套接字分配的写缓冲区满了，write方法才会阻塞，直到缓冲区中有空间空闲出来

- 即用户需要等待read将socket中的数据读取到buffer后，才继续处理接收的数据。整个IO请求的过程中，用户线程是被阻塞的，这导致用户在发起IO请求时，不能做任何事情，对CPU的资源利用率不够。

    ```
    {
    
        read(socket， buffer);
    
        process(buffer);
    
    }
    ```

    

![image-20210207152811758](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207152811758.png)







## 同步非阻塞IO模型

- 同步非阻塞IO是在同步阻塞IO的基础上，将socket设置为NONBLOCK。这样做用户线程可以在发起IO请求后可以立即返回。
- 读写方法不会阻塞，而是能读多少读多少，能写多少写多少。
- **能读多少**取决于内核为套接字分配的**读缓冲区**内部的**数据字节数**。
- **能写多少**取决于内核为套接字分配的**写缓冲区**的空闲空间**字节数**。
    有了非阻塞IO意味着线程在读写IO时可以不考虑阻塞了，读写可以瞬间完成，之后线程可以继续其他工作。
- 由于socket是非阻塞的方式，因此用户线程发起IO请求时立即返回。但并未读取到任何数据，用户线程需要不断地发起IO请求，直到数据到达后，才真正读取到数据，继续执行。

用户线程使用同步非阻塞IO模型的伪代码描述为：

```
{

    while(read(socket， buffer) != SUCCESS);

    process(buffer);

}
```



即用户需要不断地调用read，尝试读取socket中的数据，直到读取成功后，才继续处理接收的数据。整个IO请求的过程中，虽然用户线程每次发起IO请求后可以立即返回，但是为了等到数据，仍需要不断地轮询、重复请求，消耗了大量的CPU的资源。一般很少直接使用这种模型，而是在其他IO模型中使用非阻塞IO这一特性。

![image-20210207153315652](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207153315652.png)

## IO多路复用

### 原理

- IO多路复用模型是建立在内核提供的多路分离函数select基础之上的，使用select函数可以避免同步非阻塞IO模型中轮询等待的问题。
- IO 多路复用实现一个线程可以监视多个文件句柄；
- 一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；
- 没有文件句柄就绪就会阻塞应用程序，交出CPU。
- 多路是指网络连接，复用指的是同一个线程
- 服务器端采用单线程通过 select/poll/epoll 等系统调用获取 fd 列表，遍历有事件的 fd 进行 accept/recv/send ，使其能支持更多的并发连接请求。

![image-20210207153611203](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207153611203.png)

用户首先将需要进行IO操作的socket添加到select中，然后阻塞等待select系统调用返回。当数据到达时，socket被激活，select函数返回。用户线程正式发起read请求，读取数据并继续执行。

从流程上来看，使用select函数进行IO请求和同步阻塞模型没有太大的区别，甚至还多了添加监视socket，以及调用select函数的额外操作，效率更差。但是，使用select以后最大的优势是用户可以在一个线程内同时处理多个socket的IO请求。用户可以注册多个socket，然后不断地调用select读取被激活的socket，即可达到在**同一个线程内同时处理多个IO请求的目的**。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。

```c
//将socket添加到select监视中
select(socket);

while(1) {

    sockets = select();
    //一直调用select获取被激活的socket，一旦socket可读，便调用read函数将socket中的数据读取出来。

    for(socket in sockets) {

        if(can_read(socket)) {

            read(socket， buffer);

            process(buffer);
        }
    }
}
```

虽然上述方式允许单线程内处理多个IO请求，但是每个IO请求的过程还是阻塞的（在select函数上阻塞），平均时间甚至比同步阻塞IO模型还要长。如果用户线程只注册自己感兴趣的socket或者IO请求，然后去做自己的事情，等到数据到来时再进行处理，则可以提高CPU的利用率。

IO多路复用模型使用了Reactor设计模式实现了这一机制。

![image-20210207154330581](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207154330581.png)

**Reactor设计模式**

EventHandler抽象类表示IO事件处理器，它拥有IO文件句柄Handle（通过get_handle获取），以及对Handle的操作handle_event（读/写等）。继承于EventHandler的子类可以对事件处理器的行为进行定制。Reactor类用于管理EventHandler（注册、删除等），并使用handle_events实现事件循环，不断调用同步事件多路分离器（一般是内核）的多路分离函数select，只要某个文件句柄被激活（可读/写等），select就返回（阻塞），handle_events就会调用与文件句柄关联的事件处理器的handle_event进行相关操作。

![image-20210207154426634](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207154426634.png)

通过Reactor的方式，可以将用户线程轮询IO操作状态的工作统一交给handle_events事件循环进行处理。用户线程注册事件处理器之后可以继续执行做其他的工作（异步），而Reactor线程负责调用内核的select函数检查socket状态。当有socket被激活时，则通知相应的用户线程（或执行用户线程的回调函数），执行handle_event进行数据读取、处理的工作。由于select函数是阻塞的，因此多路IO复用模型也被称为异步阻塞IO模型。注意，这里的所说的阻塞是指select函数执行时线程被阻塞，而不是指socket。一般在使用IO多路复用模型时，socket都是设置为NONBLOCK的，不过这并不会产生影响，因为用户发起IO请求时，数据已经到达了，用户线程一定不会被阻塞。



用户线程使用IO多路复用模型的伪代码描述为：

```c
void UserEventHandler::handle_event() {

    if(can_read(socket)) {

        read(socket， buffer);

        process(buffer);

    }
}

//用户需要重写EventHandler的handle_event函数进行读取数据、处理数据的工作，用户线程只需要将自己的EventHandler注册到Reactor即可。
{
	Reactor.register(new UserEventHandler(socket));
}
```



Reactor中handle_events事件循环的伪代码大致如下。

事件循环不断地调用select获取被激活的socket，然后根据获取socket对应的EventHandler，执行器handle_event函数即可。

```c
Reactor::handle_events() {

    while(1) {

        sockets = select();

        for(socket in sockets) {

        	get_event_handler(socket).handle_event();

        }

    }

}
```

### select

它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以select具有O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。



- 使用事件轮询API的select函数，输入是read_fds & write_fds；输出是与之对应的可读可写事件，同时还提供了timeout参数。
- 如果期间**没有任何事件**到来，那么最多**等待timeout的值**的时间，线程处于**阻塞状态**。
- 一旦其间**有任何事件**到来，就**立即返回**。时间过了之后还是**没有任何事件**，就**立即返回**。
- **拿到事件后，线程可以继续挨个处理相应事件，处理完了继续轮询，于是线程就进入了一个死循环**，我们称循环为**时间循环**，**一个循环为一个周期**。



**select缺点**
select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是：

- 单个进程所打开的FD是有限制的，通过 FD_SETSIZE 设置，默认1024 ;
- 每次调用 select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大；需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大

- 对 socket 扫描时是线性扫描，采用轮询的方法，效率较低（高并发)。当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。



### poll

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的。

**poll缺点**
它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有缺点：

- 每次调用 poll ，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大；
- 对 socket 扫描是线性扫描，采用轮询的方法，效率较低（高并发时）



### epoll

epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是**事件驱动（每个事件关联上fd）**的，此时我们对这些流的操作都是有意义的。（复杂度降低到了O(1)）

**epoll的优点**

- 没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）；
- 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll；
- 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。





### 总结

IO多路复用是最常使用的IO模型，但是其异步程度还不够“彻底”，因为它使用了会阻塞线程的select系统调用。因此IO多路复用只能称为异步阻塞IO，而非真正的异步IO。



select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。



select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。



select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。





## 异步IO

“真正”的异步IO需要操作系统更强的支持。在IO多路复用模型中，事件循环将文件句柄的状态事件通知给用户线程，由用户线程自行读取数据、处理数据。而在异步IO模型中，当用户线程收到通知时，数据已经被内核读取完毕，并放在了用户线程指定的缓冲区内，内核在IO完成后通知用户线程直接使用即可。

![image-20210207154623278](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207154623278.png)

异步IO模型中，用户线程直接使用内核提供的异步IO API发起read请求，且发起后立即返回，继续执行用户线程代码。

目前操作系统对异步IO的支持并非特别完善，更多的是采用IO多路复用模型模拟异步IO的方式（IO事件触发时不直接通知用户线程，而是将数据读写完毕后放到用户指定的缓冲区中）。

# Redis多路IO复用模型

Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而  **I/O 多路复用** 就是为了解决这个问题而出现的。

redis的io模型主要是基于epoll实现的，不过它也提供了 select和kqueue的实现，默认采用epoll。







+ 优先选择时间复杂度为O(1)的IO复用函数作为底层实现，例如eopll
+ 以select系统调用为保底，时间复杂度O(N)
+ 基于react设计模式监听IO事件



## 基础概念

### 文件描述符

文件描述符是一个用于表述指向文件的引用的抽象化概念。 文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。







# 持久化

## RDB

是对 **Redis** 中的数据执行**周期性**的持久化。

### BGSAVE

### 优点

他会生成多个数据文件，每个数据文件分别都代表了某一时刻**Redis**里面的数据，这种方式，有没有觉得很适合做**冷备**，完整的数据运维设置定时任务，定时同步到远端的服务器，比如阿里的云服务，这样一旦线上挂了，你想恢复多少分钟之前的数据，就去远端拷贝一份之前的数据就好了。

**RDB**对**Redis**的性能影响非常小，是因为在同步数据的时候他只是**fork**了一个子进程去做持久化的，而且他在数据恢复的时候速度比**AOF**来的快。

### 缺点

**RDB**都是快照文件，都是默认五分钟甚至更久的时间才会生成一次，这意味着你这次同步到下次同步这中间五分钟的数据都很可能全部丢失掉。**AOF**则最多丢一秒的数据，**数据完整性**上高下立判。

还有就是**RDB**在生成数据快照的时候，如果文件很大，客户端可能会暂停几毫秒甚至几秒，你公司在做秒杀的时候他刚好在这个时候**fork**了一个子进程去生成一个大快照，哦豁，出大问题。




## AOF

**AOF** 机制对每条写入命令作为日志，以 **append-only** 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快，有点像Mysql中的**binlog**。

### AOF重写

### 优点

上面提到了，**RDB**五分钟一次生成快照，但是**AOF**是一秒一次去通过一个后台的线程`fsync`操作，那最多丢这一秒的数据。

**AOF**在对日志文件进行操作的时候是以`append-only`的方式去写的，他只是追加的方式写数据，自然就少了很多磁盘寻址的开销了，写入性能惊人，文件也不容易破损。

**AOF**的日志是通过一个叫**非常可读**的方式记录的，这样的特性就适合做**灾难性数据误删除**的紧急恢复了，比如公司的实习生通过**flushall**清空了所有的数据，只要这个时候后台重写还没发生，你马上拷贝一份**AOF**日志文件，把最后一条**flushall**命令删了就完事了。

### 缺点

一样的数据，**AOF**文件比**RDB**还要大。

**AOF**开启后，**Redis**支持写的**QPS**会比**RDB**支持写的要低，他不是每秒都要去异步刷新一次日志嘛**fsync**，当然即使这样性能还是很高，我记得**ElasticSearch**也是这样的，异步刷新缓存区的数据去持久化，为啥这么做呢，不直接来一条怼一条呢，那我会告诉你这样性能可能低到没办法用的，大家可以思考下为啥哟。

## 比较
你单独用**RDB**你会丢失很多数据，你单独用**AOF**，你数据恢复没**RDB**来的快，真出什么时候第一时间用**RDB**恢复，然后**AOF**做数据补全，真香！冷备热备一起上，才是互联网时代一个高健壮性系统的王道。

两种方式都可以把**Redis**内存中的数据持久化到磁盘上，然后再将这些数据备份到别的地方去，**RDB**更适合做**冷备**，**AOF**更适合做**热备**，比如我杭州的某电商公司有这两个数据，我备份一份到我杭州的节点，再备份一个到上海的，就算发生无法避免的自然灾害，也不会两个地方都一起挂吧，这**灾备**也就是**异地容灾**，地球毁灭他没办法。
**两种机制全部开启的时候，Redis在重启的时候会默认使用AOF去重新构建数据，因为AOF的数据是比RDB更完整的。**

## 策略

RDB做镜像全量持久化，AOF做增量持久化。因为RDB会耗费较⻓时间，不够实时，在停机的时候会导致⼤量丢失数据，所以需要AOF来配合使⽤。在redis实例重启时，会使⽤RDB持久化⽂件重新构建内存，再使⽤AOF重放近期的操作指令来实现完整恢复重启之前的状态。

把RDB理解为⼀整个表全量的数据，AOF理解为每次操作的⽇志就好了，服务器重启的时候先把表的数据全部搞进去，但是他可能不完整，你再回放⼀下⽇志，数据不就完整了嘛。不过Redis本身的机制是 AOF持久化开启且存在AOF⽂件时，优先加载AOF⽂件；AOF关闭或者AOF⽂件不存在时，加载RDB⽂件；加载AOF/RDB⽂件城后，Redis启动成功； AOF/RDB⽂件存在错误时，Redis启动失败并打印错误信息

对⽅追问那如果突然机器掉电会怎样？

取决于AOF⽇志sync属性的配置，如果不要求性能，在每条写指令时都sync⼀下磁盘，就不会丢失数据。但是在⾼性能的要求下每次都sync是不现实的，⼀般都使⽤定时sync，⽐如1s1次，这个时候最多就会丢失1s的数据。

对⽅追问RDB的原理是什么？

你给出两个词汇就可以了，fork和cow。fork是指redis通过创建⼦进程来进⾏RDB操作，cow指的是copy on write，⼦进程创建后，⽗⼦进程共享数据段，⽗进程继续提供读写服务，写脏的⻚⾯数据会逐渐和⼦进程分离开来。

# LRU

最近最少使用缓存机制

算法核心是哈希+链表

本质就是HashMap+DoubleLinkedList

时间复杂度`O(1)`

## LinkedHashMap

```java
import java.util.LinkedHashMap;
import java.util.Map;

public class Main<K，V> extends LinkedHashMap<K，V> {
    private int capacity;

    public Main(int capacity) {
        super(capacity，0.75F，true);
        this.capacity = capacity;
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry<K， V> eldest) {
        return super.size() > capacity;
    }

    public static void main(String[] args) {
        Main main = new Main(3);
        main.put(1， "a");
        main.put(2， "b");
        main.put(3， "c");
        main.get(1);
        main.put(4， "d");
        //[3， 1， 4]
        System.out.println(main.keySet());
    }
}
```

## 只用HashMap

```java
import java.util.HashMap;
import java.util.Map;

public class Main<K， V> {
    class Node<K， V> {
        K key;
        V value;
        Node<K， V> prev;
        Node<K， V> next;

        public Node() {
        }

        public Node(K key， V value) {
            this.key = key;
            this.value = value;
        }
    }

    class DoubleLinkedList<K， V>{
        Node<K， V> head;
        Node<K， V> tail;

        public DoubleLinkedList() {
            head = new Node<>();
            tail = new Node<>();
            head.next = tail;
            tail.prev = head;
        }

        public void addHead(Node<K， V> node) {
            node.next = head.next;
            node.prev = head;
            head.next.prev = node;
            head.next = node;
        }

        public void removeNode(Node<K， V> node) {
            node.next.prev = node.prev;
            node.prev.next = node.next;
            node.prev = null;
            node.next = null;
        }

        public Node<K， V>  getLast() {
            return tail.prev;
        }
    }

    private int cacheSize;
    private Map<Integer， Node<Integer， Integer>> map;
    DoubleLinkedList<Integer， Integer> doubleLinkedList;

    public Main(int cacheSize) {
        this.cacheSize = cacheSize;
        map = new HashMap<>();
        doubleLinkedList = new DoubleLinkedList<>();
    }

    public int get(int key) {
        if (!map.containsKey(key)) {
            return -1;
        }
        Node<Integer， Integer> node = map.get(key);
        doubleLinkedList.removeNode(node);
        doubleLinkedList.addHead(node);
        return node.value;
    }

    public void put(int key， int value) {
        if (map.containsKey(key)) {
            Node<Integer， Integer> node = map.get(key);
            node.value = value;
            map.put(key， node);
            doubleLinkedList.removeNode(node);
            doubleLinkedList.addHead(node);
        }
        else {
            if (map.size() == cacheSize) {
                Node<Integer， Integer> last = doubleLinkedList.getLast();
                map.remove(last.key);
                doubleLinkedList.removeNode(last);
            }
            Node<Integer， Integer> node = new Node<>(key， value);
            map.put(key， node);
            doubleLinkedList.addHead(node);
        }
    }

    public static void main(String[] args) {
        Main main = new Main(3);
        main.put(1， 1);
        main.put(2， 2);
        main.put(3， 3);
        main.get(1);
        main.put(4， 4);
        //[3， 1， 4]
        System.out.println(main.map.keySet());
    }
}
```