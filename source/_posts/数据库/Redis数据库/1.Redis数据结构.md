---
title: Redis数据结构
author: tongji4m3
top: true
cover: false
coverImg: /images/1.jpg
toc: true
mathjax: false
summary: 包括了Redis底层数据结构、基本数据结构、高级数据结构（HyperLogLog、Bloom Filter）等。
categories: Redis
tags:
  - 数据结构
  - 对象
  - 开源框架
abbrlink: 85682d75
date: 2020-11-01 00:00:00
---



# 底层数据结构

## 简单动态字符串

### SDS简介

+ 使用**简单动态字符串**(simple dynamic string SDS)作为默认字符串
+ c字符串只作为字符串字面量，用在无需对字符串值进行修改的地方
+ 包含字符串值的键值对在底层都是用SDS实现的

### SDS的定义

```c
struct sdshdr
{
	int len;//记录buf数组中已使用字节的数量 为字符串长度
	int free;//未使用的数量
	char buf[];//字节数组，用来保存字符串
}
```

1. buf数组以空字符结尾，且最后的空字符不算在len里面
2. 该空字符由SDS函数自动完成，对SDS用户透明

### SDS与C字符串的区别

#### 获取字符串长度所需复杂度从O(N)降低到​O(1)​

#### 杜绝了缓冲区溢出

例如c进行字符串拼接，需要假设已经为字符串分配了足够的内存以容纳要拼接的字符串，否则就会溢出。
**SDS空间分配策略**完全杜绝了发生缓冲区溢出的可能性。当要对SDS进行修改时，会先检查空间是否满足修改所需的要求，如果不满足，则会自动将**SDS的空间扩展**，然后再执行实际的修改操作

#### 减少修改字符串时带来的内存重分配次数

C字符串底层实现总是一个N+1个字符长的数组，每次对该数组进行增加或缩短，总要进行一次**内存重分配**操作。如果是增长，则要内存重分配扩展底层数组的空间大小。如果是缩短，则执行操作后，需要内存重分配来释放空间，避免内存泄漏。

Redis通过**未使用空间**解除了字符串长度和底层数组长度之间的关联

##### 空间预分配

用于优化SDS的字符串增长操作，在扩展SDS空间之前，会先检查未使用的空间是否足够，如果足够，则直接使用未使用空间，无需进行内存重分配。

在对一个SDS进行修改，并且需要对SDS进行空间扩展时，不仅为SDS分配修改所需要的空间，还会分配额外的未使用空间。

如果修改后 SDS.len < 1MB，程序会分配给和len一样的长度给free

如果修改后 SDS.len >= 1MB，程序会分配1MB给free

##### 惰性空间释放

用于优化SDS字符串缩短操作：不立即回收缩短后多出来的字节，而是用free记录。避免了缩短字符串时所需的内存重分配操作，并且为将来可能的增长提供了优化

API也让我们在需要时，真正释放SDS的未使用空间，不用担心惰性空间释放策略会造成内存浪费

#### 二进制安全

1. C字符串并且符合特定的编码，并且除字符串的末尾外，不能包含空字符，使得他只能保存文本数据
2. Redis以处理二进制的方式处理SDS存放在buf数组的数据，使用len而不是空字符判断字符串是否结束。所以他可以保存**任意格式**的二进制数据。

#### 兼容部分C字符串函数

SDS保存数据的末尾总是为空字符，所以让那些保存文本数据的SDS可以重用一部分<string.h>库'定义的函数

## 链表

被广泛用于实现Redis的各种功能，如列表键，发布与订阅，慢查询，监视器等等

### 链表和链表节点的实现

```c
typedef struct listNode
{
	struct listNode * prev;
	struct listNode * next;
	void * value;
}listNode;
```

```c
typedef struct list
{
	listNode *head;
	listNode *tail;
	unsigned long len;
	
	void *(*dup)(void *ptr);//节点值的复制函数
	void (*free)(void * ptr);//节点值的释放函数
	int (*match)(void * ptr，void * key);//节点值的对比函数
}
```

### 特性总结

+ 双端、无环、带表头和表尾指针、带链表长度计数器
+ 多态：可以保存各种不同类型的值



## 字典

Redis的数据库底层就是用字典实现的

字典也是**哈希键**的底层实现之一

### 字典的实现

字典采用哈希表作为底层实现，一个哈希表可以有多个哈希表节点，每个节点保存了一个键值对

每个字典带有**两个哈希表**，一个平时使用，一个仅仅在rehash时使用

### 哈希表

```c
typedef struct dictht
{
	dictEntry ** table;//哈希表数组
	unsigned long size;
	unsigned long sizemask;//哈希表大小掩码，用于计算索引值 总=size-1
	unsigned long used;
}dictht;
```

sizemask和哈希值一起决定一个键应该放到table数组里面的哪个索引上

### 哈希表节点

```c
typedef struct dictEntry
{
	void *key;
	union
	{
		void *val;
		uint64_t u64;
		int64_t s64;
	} v;
	struct dictEntry * next; 
}dictEntry;
```

值可以是应该指针，或者是应该uint64_t类型的整数，或是一个int64_t整数

next属性指向另一个哈希表节点的指针，可以将多个哈希值相同的键值对连接在一起，以解决键冲突

### 字典

```c
typedef struct dict
{
	dicType * type;//类型特定函数
	void * privdata;//私有数据
	ditcht ht[2];//哈希表
	
	int rehashidx;//rehash索引，当rehash不再进行时，值为-1
}dict;
```

1. type，privdata属性是针对不同类型的键值对，为创建多态字典而设置的
2. 每个dicType结构保存了一簇用于操作特定类型键值对的函数
3. privdata属性保存了需要传给那些类型特定函数的可选参数
4. ht数组中，每个项都是**ditcht哈希表**，一般只使用ht[0]，ht[1]只会在ht[0]进行rehash时使用
5. rehashidx记录rehash目前的进度

### 哈希算法

程序先通过键计算哈希值hash，在计算索引(hash & sizemask)，再根据索引将包含新键值对的哈希表节点放到哈希表数组的指定索引上

### 解决键冲突

用链地址法，多个分配到同一个索引的节点用单向链表连接起来。且用**头插法**，将新节点添加到链表的表头位置 

### rehash

#### 时机

1. 若没有在执行BGSAVE或BGREWRITEAOF命令，则哈希表负载因子大于等于1时rehash
2. 若在执行BGSAVE或BGREWRITEAOF命令，则哈希表负载因子大于等于5时rehash
3. load_factor=ht[0].used / ht[0].size
4. 以上的不同是因为，执行那两个命令时，Redis需要创建当前服务器进程的**子进程**，在子进程存在期间，服务器会提高执行扩展操作所需的负载因子，从而京可能避免在子进程存在期间进行哈希表的扩展操作，可以避免不必要的内存写入操作，最大限度地节约内存
5. 当负载因子小于0.1，则自动进行收缩操作

#### 步骤

1. 为字典的ht[1]哈希表分配空间
    - 如果是扩展，则ht[1]大小为第一个大于等于 ht[0].used * 2 的2^n​。
    - 如果是收缩，则是第一个大于等于 ht[0].used 的2^n​。
2. 将保存在ht[0]的所有键值对rehash到ht[1]上面，即重新计算哈希值和索引值，然后放到ht[1]的指定位置上
3. 当ht[0]所有的键值对都迁移到了ht[1]，则将ht[1]设置为ht[0]，并且在ht[1]新建一个空哈希表

### 渐进式rehash

1. rehash时，服务器不是一次就将ht[0]里面的所有键值对全部rehash到ht[1]。而是分多次，**渐进式**地将ht[0]里面的键值对慢慢地rehash到ht[1]
2. 在执行操作之外，顺带将键值对rehash到ht[1]中，把rehash键值对所需的计算工作均摊到每次对字典的增删改查操作之中。当rehash工作完成后，将rehashidx属性的值加一。所有的键rehash完毕后，rehashidx设置为-1
3. 在进行渐进式rehash时，字典**同时**使用ht[0]，ht[1]。所以操作同时在两个哈希表中进行，即如果要查找一个键，会先在ht[0]找，没找到就继续到ht[1]中找
4. 新添加的键值对直接保存到ht[1]中



## 跳跃表

### 简单记忆

跳表具有如下性质：

(1) 由很多层结构组成

(2) 每一层都是一个有序的链表

(3) 最底层(Level 1)的链表包含所有元素

(4) 如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。

(5) 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。

![](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/151153099856214.jpg)

例子：查找元素 117

(1) 比较 21， 比 21 大，往后面找

(2) 比较 37,  比 37大，比链表最大值小，从 37 的下面一层开始找

(3) 比较 71,  比 71 大，比链表最大值小，从 71 的下面一层开始找

(4) 比较 85， 比 85 大，从后面找

(5) 比较 117， 等于 117， 找到了节点。

```c
/* 如果存在 x, 返回 x 所在的节点， 
 * 否则返回 x 的后继节点 */  
find(x)   
{  
    p = top;  
    while (1) {  
        while (p->next->key < x)  
            p = p->next;  
        if (p->down == NULL)   
            return p->next;  
        p = p->down;  
    }  
}  
```



### 特性

+ 通过在每个节点中维持多个指向其他节点的指针，从而快速访问节点
+ 查找速度:平均O(log N)，最坏O(N)
+ 支持顺序性操作
+ 使用跳跃表作为有序集合键的底层实现之一

- 因为要进行随机的插入和删除，不便用数组

- 要定位插入位置一般用二分查找

- 层级制，最下面所有元素串起来，每隔几个元素挑选一个代表，再将这几个代表用另外一级指针串起来，然后继续选出二级代表，最后形成金字塔结构

- 插入，先在顶层定位，然后下潜到下一级定位，一直下潜到最底层找到合适的位置，将新元素插入进去

- 随机策略，位于L0层概率为1，兼职L1层概率0.5，到L2层0.25，概率逐层降低


### 性质

1. 每一层都是一个有序的链表，最底层(L1)的链表包含**所有元素**
2. 如果一个元素出现在第 n 层的链表中，则它也出现在第 n-1 层
3. 搜索先从上层搜索，当前面的元素比target大时，则向下一级搜索(即向着更密集的数据找)
4. 总体来看从左上往右下寻找

### 查找代码

从每个节点的最高层开始寻找，如果该层forward不为null，并且分值小于score，则跳到下一个节点，即x = x->level[i].forward，然后如果相等，则返回。如果该层的forward不满足，则遍历自己的下一个层级(level[i-1])的位置。综上就是从左往右，从上往下。

```c
// 通过分值和对象值获取排位信息，以1为起始值
unsigned long zslGetRank(zskiplist *zsl， double score， robj *o) {
    zskiplistNode *x;
    unsigned long rank = 0;
    int i;

    x = zsl->header;
    // 从最高层依次往下
    for (i = zsl->level-1; i >= 0; i--) {
        while (x->level[i].forward &&
            (x->level[i].forward->score < score ||
                (x->level[i].forward->score == score &&
                compareStringObjects(x->level[i].forward->obj，o) <= 0))) {
            // 排位增加
            rank += x->level[i].span;
            x = x->level[i].forward;
        }

        /* x might be equal to zsl->header， so test if obj is non-NULL */
        // 对象和分数值都相等
        if (x->obj && equalStringObjects(x->obj，o)) {
            return rank;
        }
    }
    return 0;
}
```

### 原理

![IMG_20200818_102630](https://tongji4m3.oss-cn-beijing.aliyuncs.com/IMG_20200818_102630.jpg)

level:表中层数最大的节点的层数

length:节点数量

### 跳跃表节点

```c
typedef struct zskiplistNode
{
	struct zskiplistNode * backward;//后退指针
	double score;//分值
	robj * obj;//成员对象
	
	struct zskiplistLevel //层
	{
		struct zskiplistNode * forward; //前进指针
		unsigned int span;//跨度
	} level[];
}
```

#### 层

level数组可以包含多个元素，每个元素都包含一个指向其他节点的指针，来加快访问其他节点的速度

感觉幂次规律，随机生成一个[1，32]的值作为level数组的大小，即层的高度

#### 前进指针

每个层都有一个指向表尾方向的前进指针(level[i].forward)

#### 跨度

记录两个节点之间的距离

指向NULL的所有前进指针的跨度都为0

跨度实际是用来计算排位的:在查找某个节点过程中，将沿途访问的所有层的跨度累积起来，得到的结果就是目标节点在跳跃表中的排位(即该节点是第几个节点)

#### 后退指针

可以先通过跳跃表的tail指针访问表尾节点，然后通过后退指针访问倒数第二个节点...，直到遇到指向NULL的后退指针

#### 分值和成员

1. 分值:跳跃表中所有节点都按分值从小到大排序
2. 成员对象:指向**SDS字符串**对象的指针
3. 跳跃表中成员对象必须唯一，但是分值可以相同
4. 分值相同的节点按照成员变量的字典序排序

### 跳跃表结构

```c
typedef struct zskiplist
{
	struct zskiplistNode * header，*tial;
	unsigned long length;//表中节点的数量
	int level;//表中层数最大的节点的层数
} zskiplist;
```

使得能O(1)访问表头表尾节点，访问跳跃表长度，获取表中层数最大的节点的层数

## 整数集合

当一个集合只包含整数值元素，并且数量不多时，redis就会采用整数集合作为集合键的底层实现

```c
typedef strcut intset
{
	uint32_t encoding; //编码方式
	uint32_t length; //元素数量
	int8_t contents[]; //保存元素的数组
}
```

可以保存类型为 int16_t，int32_t，int64_t的**非重复**整数值，且元素在contents数组中**有序排列**

### 升级

每当添加一个新元素到整数集合里面，并且新元素的类型比**现有所有元素类型**都长，需要先对整数集合进行升级，再加入该元素

1. 根据新元素类型，扩展整数集合底层数组的空间大小，并为新元素分配空间
2. 将底层数组现有的**所有元素转换**成与新元素相同的类型，并且放置到正确位置上，仍需**保证有序性**
3. 将新元素添加到底层数组里

每次添加新元素都有可能引起升级，而每次升级都需要对底层数组所有元素进行类型转换，所以添加新元素时间复杂度为O(N)

### 升级的好处

#### 提升灵活性

整数集合可以通过自动升级底层数组来适应新元素，所以可以将 int16_t、int32_t、int64_t随意地添加到集合中，不必担心类型错误

#### 节约内存

既可以让集合能**同时保存三种不同类型**的值，又可以确保升级只在必要时进行

### 降级

**不支持**降级操作，即使把之前因为他而升级的元素删除，底层数组还仍然是加入那个元素后的类型



## 压缩列表

### 特点

- **（1）内存空间连续：**ziplist为了提高存储效率，从存储结构上看ziplist更像是一个表(list)，但不是一个链表(linkedlist)。ziplist将每一项数据存放在前后连续的地址空间内，一个ziplist整体占用一大块内存。而普通的双向链表每一项都占用独立的一块内存，各项之间用指针连接，这样会带来大量内存碎片，而且指针也会占用额外内存。
- **（2）查询元素：**查找指定的数据项就会性能变得很低，需要进行遍历整个zipList。
- **（3）插入和修改：**每次插入或修改引发的重新分配内存(realloc)操作会有更大的概率造成内存拷贝，从而降低性能。跟list一样，一旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更大的一块数据。

ziplist提高了存储效率，是内存紧缩的列表，多个数据在一起的连续空间，不擅长修改，在两端pop,push快。

### 理解

压缩链表同样具有一定的劣势。压缩链表由于使用的是有一段连续的内存，这就意味着，执行插入操作导致内存大小发生变化时，便会引起一次内存的重新分配过程，同时还会执行一定量的数据移动。特别是对于压缩链表较长的情况下，大批量的数据移动势必会降低系统的性能。而在上述这个方面恰恰就是经典双端链表的优势，故此*Redis*设计实现了一种快速链表的数据结构，兼具经典双端链表与压缩链表的特点，实现了时间与空间上的一种折衷。



链表存在一个问题，便是在存储小数据的时候， 内存使用效率过低，例如当一个链表节点中只保存一个字节的`unsigned char`数据时，我们需要为这个节点保存24个字节的额外数据， 其中包含`listNode.prev`指针，`listNode.next`指针，以及指向具体数据的`listNode.value`指针， 同时对于链表节点所占用内存的反复申请与释放，也容易导致内存碎片的产生。 为了解决经典双端链表在保存小数据而导致内存效率过低的问题，*Redis*设了一套压缩链表的数据数据结构*ziplist*来对这种场景下的链表应用进行优化。

压缩链表允许在链表两端以 *O(1)* 的时间复杂度执行 *Pop* 或者 *Push* 操作，当然这只是一种理想状态下的情况， 由于压缩链表实际上是内存中一段连续分配的内存，因此这些操作需要对压缩链表所使用的内存进行重新分配， 所以其真实的时间复杂度是和链表所使用的内存大小相关的。

压缩链表与经典双端链表最大的区别在于，双端链表的节点是分散在内存中并不是连续的，压缩链表中所有的数据都是存储在一段连续的内存之中的



压缩链表是相对于普通链表而言的

当普通链表的数据越来越多, 链表查询性能会低效

当存储的数据较少时, 使用链表存储会浪费空间

压缩链表本质上是一个字符串

压缩链表内存储的数据只能是 整型, 字符串

### 具体

- 压缩列表是列表键和哈希键的底层实现之一
- 当一个列表键只包含**少量列表项**，并且每个列表项都是**小整数或较短字符串**，则用压缩列表作为底层实现
- 压缩列表是为了**节约内存**而开发的，是由一系列特殊编码的连续内存块组成的**顺序型数据结构**
    - zlbytes：记录整个压缩列表所占用的内存字节数，在内存重分配或zlend位置时使用
    - zltail：记录压缩列表表尾节点距压缩列表的起始地址有多少字节，通过该偏移量，可无须遍历整个压缩列表就可以确定表尾节点的地址
    - zllen：记录了压缩列表包含的节点数量
    - entryX：压缩列表包含的各个节点，节点长度由节点包含的内容决定
    - zlend：特殊值0xFF，用于标记压缩列表的末端

![image-20210207091430874](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207091430874.png)

### 压缩列表节点的构成

![image-20210207091652786](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207091652786.png)

#### previous_entry_length

- 记录压缩列表**前一个节点**的长度
- 通过指针运算，根据当前节点的起始地址得到前一个节点的起始地址
- 用于从表尾到表头的遍历：指向表尾节点的指针可以通过压缩列表的起始地址的指针加上zltail得到

#### encoding

记录节点的content属性所保存数据的类型及长度

#### content

负责保存节点的值，值的类型和属性由encoding决定

#### 连锁更新

- 每个节点的previous_entry_length属性都记录了前一个节点的长度，如果前一节点长度小于254字节，则previous_entry_length属性用1字节空间保存该长度值，否则需要用5字节空间。
- 如果在压缩列表中，有多个介于[250，153]字节的节点[e1，eN]，记录这些节点的长度只需要1字节长的**previous_entry_length**，所以[e1，eN]所有节点的**previous_entry_length**都是1字节长

- 但如果将一个大于254字节的新节点new加入压缩列表的头节点，则new成为e1的前置节点。而这样e1的**previous_entry_length**属性不足以保存new的长度，所以进行空间重分配，变成5字节大小

- 这样e1的长度大于254字节了，e2的**previous_entry_length**也不足以保存e1的长度，也扩展成5字节大小。这样就进行连续多次空间扩展，即连锁更新

- 删除节点也会引发连锁更新
- 连锁更新在最坏情况下需要对压缩列表进行N次空间重分配操作，每次操作最坏O(N)，所以连锁更新最坏时间复杂度为O(N^2)​.
- 但是发生的机率比较低：
    - 恰好有多个连续的，长度介于250-153字节的节点的情况并不多见 
    - 即使出现连锁更新，只要被更新的节点数量不多，就不会对性能有影响
- 所以平均复杂度为O(N)

## 快速链表

- 双向链表便于在表的进行插入和删除节点操作，但是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针；其次，双向链表的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。
- ziplist由于是一整块连续内存，所以存储效率很高。但是，它不利于修改操作，每次数据变动都会引发一次内存的内存重新分配(realloc)。特别是当ziplist长度很长的时候，一次realloc可能会导致大批量的数据拷贝，进一步降低性能。

可见，一个quicklist节点上的ziplist要保持一个合理的长度

**quicklist将 双向链表插入和修改元素不需要移动节点的优点 和 ziplist的存储效率很高优点(一整块连续内存)结合在一起，同时将各自的缺点进行一个折中的处理。**

### 使用原因

链表在早先的 redis 版本中也作为 list 的数据结构使用过，但是单纯的链表的缺陷之前也说了，插入便利，但是空间利用率低，并且不能进行二分查找等，检索效率低，ziplist 压缩表的产生也是同理，希望获得更好的性能，包括存储空间和访问性能等

作者结合了经典双端链表以及压缩链表的特性，实现了快速链表的数据结构。简单来说，使用双端链表的形式描述整个快速链表，而每一个快速链表的节点都是使用一个压缩链表作为底层数据存储，可以存储若干个数据节点。同时基于链表数据结构通常对头部与尾部的访问最为频繁，而对链表中间的数据访问并不是特别频繁，因此出于节省空间的目的，会对中间节点底层压缩链表所使用的内存进行压缩

### 理解

quicklist 里有 head，tail, quicklistNode里有 prev，next 指针，是不是有链表的基本轮廓了

关键就在这个`unsigned char *zl;`zl 是不是前面又看到过，就是 ziplist ，这是什么鬼，

链表里用压缩表

回顾下前面说的 ziplist，ziplist 有哪些特点，内存利用率高，可以从表头快速定位到尾节点，节点可以从后往前找，但是有个缺点，就是从中间插入的效率比较低，需要整体往后移，这个其实是普通数组的优化版，但还是有数组的一些劣势，所以要真的快，是不是可以将链表跟数组真的结合起来。

假如每个快表节点的 ziplist 只放一个元素，那么其实这就退化成了一个链表，如果 10 个元素放在一个 quicklistNode 的 ziplist 里，那就退化成了一个 ziplist

quickList 是 zipList 和 linkedList 的混合体，它将 linkedList 按段切分，每一段使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。

![](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/1294391-20180827151851500-1561398239.png)

  

# 基本数据结构

## 字符串对象

1. 字符串对象的编码可以是int，raw，embstr
2. 如果字符串对象保存整数值，且可以用long表示，则会将整数值保存在ptr中，enconding设为int
3. 如果保存字符串值，并且长度大于39字节，就用`SDS`保存，并且设为raw
4. 如果保存字符串值，并且长度小于39字节，就用`embstr`编码保存，并且设为embstr

#### embstr

专门用来保存短字符串的一种优化编码方式，和SDS差不多
不同的是，只调用一次内存分配函数来分配一块连续的空间，空间依次包含redisObject，sdshdr两个结构
优点：内存分配与释放次数由两次变为一次；字符串所有的数据保存在一块连续的内存中，更好利用缓存

#### 编码的转换

1. int编码的字符串对象如果操作后保存的不再是整数值，而是字符串值，则编码变为raw
2. embstr编码的字符串对象只是可读的，对它执行任何修改命令，都会编程raw

**应用**

+ 点赞数量:  incr likes 每操作一 次，就+1，最后可以通过get likes得到最终结果
+ 将用户信息使用JSON序列化为字符串，将字符串塞进Redis来缓存
+ 如果value是整数，则可以进行自增操作。用于计数器：可以快速实现计数和查询的功能。

## 列表对象

编码可以是`ziplist`,`linkedlist`。ziplist使用压缩列表作为底层实现，linkedlist采用双端链表作为底层实现。每个双端链表节点都保持一个字符串对象（之后使用的是quickList)

字符串对象是Redis 5种类型的对象中唯一一种会被其他四种对象嵌套的对象

#### 编码转换

使用ziplist编码的情况：

1. 列表对象保存的所有字符串元素都小于64字节
2. 列表保存的元素数量小于512

**理解**

+ 相当于LinkedList，是链表不是数组，插入删除快，索引定位慢
+ 元素较少时会使用一块连续内存存储，即ziplist（压缩列表），所有元素彼此紧挨着一起存储
+ 元素较多时采用快速链表（quicklist），将多个ziplist使用双向指针串起来使用，既满足快速插入删除，又不会出现太大空间冗余

**应用场景**

+ 粉丝列表、文章的评论列表

+ 通过 lrange 命令，读取某个闭区间内的元素，可以基于 List 实现分页查询，这个是很棒的一个功能，基于 Redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走。

+ 消息队列（异步队列）：数据的生产者可以通过Lpush命令从左边插入数据，多个数据消费者，可以使用BRpop命令阻塞的“抢”列表尾部的数据。

## 哈希对象

编码可以是ziplist、hashtable。

用ziplist则将键值对压入列表表尾，键值对紧挨一起，键在前，值在后。类似队列

hashtable编码用字典作为底层实现，字典的每个键与值都是一个字符串对象

#### 编码转换

使用ziplist编码的情况：

1. 列表对象保存的所有字符串元素都小于64字节
2. 列表保存的元素数量小于512

**应用**

- 类似与Map<String，Map<String，String>

- 和HashMap一样采用数组+链表

- Redis字典的值只能是字符串

- 渐进式rehash策略：在rehash时保留新旧两个hash结构，查询时会同时查询两个hash结构，循序渐进的将旧hash的内容一点点地迁移到新的hash结构中

- 记录帖子的点赞数、评论数、点击数

## 集合对象

编码可以是intset、hashtable。

用intset编码的集合使用整数集合作为底层实现

用hashtable编码的集合使用字典作为底层实现，每个键是一个字符串对象，而值设为NULL

#### 编码转换

使用intset编码的情况：

1. 列表对象保存的都是整数值
2. 列表保存的元素数量小于512



**set**

- 相当于HashSet，键值对是无序的、唯一的。相当于所有value都是NULL的hash

- 统计中奖的用户ID，可以去重


+ 交集运算:微博共同关注 SINTER key1 key2
+ 朋友圈点赞
+ 抽奖活动
    + SADD key 添加参与
    + SCARD key 查看有几个人参与了抽奖
    + SRANDMEMBER key 2 随机抽两个人，不删除
    + SPOP key 随机抽取并删除1个人

## 有序集合对象

有序集合的编码可以是ziplist、skiplist

用ziplist编码则每个集合元素使用两个紧挨的压缩列表节点来保存，第一个节点保存元素的成员，第二个保存元素的分值。集合元素按分值从小到大进行排序

#### 用skiplist编码实现

同时包含一个**字典**和**跳跃表**

```c
typedef struct zset
{
	zskiplist *zsl;
	dict * dict;
} zset;
```

zset中的zsl跳跃表按分值从小到大保存了所有集合元素

每个跳跃表节点中：object属性保存元素的成员，score属性保存元素的分值

此外，dict中，字典的键保存元素的成员，值保存元素的分值，这样，通过字典可以用O(1)的复杂度查找给定成员的分值

这两种数据结构都会通过指针来共享相同元素的成员和分值，所以使用跳跃表和字典来保存集合元素不会产生任何重复成员或者分值，不会浪费额外内存

优点：

+ 范围操作不需要对字典保存的所有元素进行排序，从O(NlogN)到O(N)
+ 根据成员查询分值不需要通过跳跃表，复杂度从O(N)降低到O(1)

#### 编码转换

使用ziplist编码的情况：

1. 有序集合保存的所有元素长度都小于64字节
2. 有序集合保存的元素数量小于128个

**应用**

+ 类似于SortedSet和HashMap的结合体，保证了value的唯一性，每个value有score（排序权重）

+ 热搜

+ 游戏排名

+ 排行榜：榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。

+ 微博热搜榜，value是名称，score是热度值

+ 粉丝列表，value是粉丝用户ID，score是关注时间

+ 学生成绩，value是学生ID，score是考试成绩

## 对象特性

### 简介

1. 基于之前的数据结构创建一个对象系统。包括字符串对象，列表对象，哈希对象，集合对象，有序集合对象五种
2. 可以在执行命令之前，根据对象类型判断一个对象能否执行给定的命令
3. 可以针对不同的使用场景，为对象设置多种不同的数据结构实现，从而优化对象在不同场景下的使用效率
4. 实现基于引用计数的内存回收机制，实现内存共享机制，让多个数据库键共享同一个对象节约内存
5. 对象带有访问时间记录信息，记录数据库键的空转时间

**理解**

每个键值对都是由对象组成，键总是一个字符串对象，值可以是五种对象中的一种

如果容器不存在，则先创建一个再进行操作

如果容器里元素为空，则立刻删除容器，释放内存

### 对象的类型和编码

使用对象来表示数据库的键和值，新创建一个键值对时，会创建两个对象分别代表键和值

```c
typedef struct redisObject
{
	unsigned type:4;//类型
	unsigned encoding:4;//编码
	void * ptr;//指向底层实现数据结构的指针
}
```

#### 类型

`type`属性记录了对象的类型，即五种对象类型之一
对于一个键值对，键总是字符串对象，值可以是五种对象类型之一

#### 编码和底层实现

1. 对象的ptr指针指向对象的底层实现数据结构，而这些数据结构由对象的encoding属性决定，即之前学习的几种数据结构
2. 每种类型的对象都至少使用了两种不同的编码
3. 通过`encoding`属性来设定使用的编码，极大地提升了灵活性和效率，可以根据不同的使用场景来为一个对象设置不同的编码，从而优化对象在某一场景下的效率

### 类型检查和命令多态

在执行一个类型的特定命令之前，服务器会检查输入数据库键的值对象是否为执行命令所需的指令，如果是，服务器就会对键执行指定的命令。否则将拒绝执行命令，并向客户端返回一个类型错误。

类型检查是通过`redisObject`结构的type属性来实现的 

#### 多态命令的实现

Redis除了会根据值对象的类型来判断键是否能够执行指定指令之外，还会根据值对象的编码方式，选择正确的命令实现代码来执行命令

例如，`LLEN命令`是多态的，只要执行LLEN命令的是列表键，那么无论值对象使用的是ziplist编码还是linkedlist编码，命令都可以正常执行

DEL，TYPE等命令也是多态命令，无论输入的键是什么类型，这些命令都可以正常执行。区别在于，DEL，TYPE等命令是基于类型的多态，一个命令可以处理多种不同的类型的键，LLen命令是基于编码的多态，一个命令可以同时用于处理多种不同编码

### 内存回收

基于引用计数法实现内存回收机制，通过跟踪对象的引用计数信息，在适当的时候自动释放对象并进行内存回收

1. 创建对象，引用计数值为1
2. 对象被新程序使用，引用计数值+1
3. 对象不被一个程序使用，引用计数值-1
4. 引用计数值为0时，释放对象占用的内存

### 对象共享

#### 步骤

让多个键共享同一个值对象步骤：

1. 将数据库键的值指向一个现有的值对象
2. 将被共享的值对象引用计数值+1

#### 内置整数

Redis在初始化服务器时，会创建一万个字符串对象，存储[0,9999]的整数值。如果需要用到这些字符串对象，服务器则会使用这些共享对象，而不会新创建对象。

这些共享对象不仅仅只有字符串键可以使用，那些在数据结构中嵌套了字符串对象的对象都可以使用这些共享对象

#### 为什么不共享包含字符串的对象

只有在共享对象和目标对象完全相同的情况下，程序才会将共享对象用作键的值对象

一个共享对象保存的值越复杂，则验证共享对象和目标对象是否相同所需的复杂度越高：

1. 共享对象是整数值的字符串对象，验证操作为`O(1)`
2. 共享对象是保存字符串值的字符串对象，验证操作为`O(N)`
3. 共享对象是包含多个值的对象（如列表），验证操作为`O(N^2)`

### 对象的空转时间

`redisObject`结构包含属性lru,记录了对象最后一次被命令程序访问的时间。可用当前时间-键的值对象的lru时间求得空转时间

可通过设置，使得当服务器占用的内存数超过了，`maxmemory`的上限时，空转时间较高的那部分键会优先被服务器释放，从而回收内存

# 高级数据结构

## 位图bitmap

位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组

可以使用get/set 直接获取和设置整个位图的内容，也可以使⽤位图操作 getbit/setbit 等将 byte 数组看成「位数组」来处理。

位数组会自动扩展，如果设置了某个偏移位置超出了现有的内容范围，就会自动进行零扩充



**应用场景**

用户签到

+ 有些bool 型数据需要存取，例如用户⼀年的签到记录，签了是 1，没签是0，要记录 365 天
+ 位图数据结构让每天的签到记录只占据⼀个位，365 天就是 365个位，46 个字节 (⼀个稍长⼀点的字符串) 就可以完全容纳下
+ 统计和查找
    + bitcount：统计指定范围内1的个数，可以统计用户一共签到多少天 
    + bitpos：用于查找指定范围内出现的第一个0或1，从哪天开始第一次签到

## HyperLogLog

+ 提供不精确的去重统计方案，标准误差是0.81%
+ 不能知道一个值是否在结构中，即不提供 pfcontains功能

+ pfadd 和 pfcount，⼀个是增加计数，⼀个是获取计数。pfadd codehole user1（将用户ID塞进去）；pfcount codehole
+ pfmerge：用于将多个pf计数值累加在一起形成一个新的pf值，例如两个差不多的页面进行合并，需要将页面的UV访问量也合并
+ 场景：UV（Unique Visitor） 需要去重，同⼀个用户⼀天之内的多次访问请求只能计数⼀次。
+ 实现：计数较小时使用稀疏矩阵存储，占用空间超过阈值，则转成稠密矩阵

## Bloom Filter

### 定义

布隆过滤器是一个很长的二进制向量和一系列随机映射函数。

优点是空间效率和查询时间都远远超过⼀般的算法

### 原理

当⼀个元素被加入集合时，通过K个散列函数将这个元素映射成⼀个位数组中的K 个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（⼤约）知道集合中有没有它了：如 果这些点有任何⼀个0，则被检元素⼀定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。

Bloom Filter跟单哈希函数Bit-Map不同之处在于：Bloom Filter使⽤了k个哈希函数，每个字符串跟k个 bit对应。从⽽降低了冲突的概率。

### 特点

+ 是一个很长的二进制向量和一系列随机映射函数
+ 当⼀个元素被加入集合时，通过K个散列函数将这个元素映射成⼀个位数组中的K 个点，把它们置为1
+ exists：把hash的几个位置都算出来，看看位数组在几个位置是否都为1
    + 如果这些点有任何⼀个0，则被检元素⼀定不在
    + 如果都是1，则被检元素很可能在
+ 空间效率和查询时间都远远超过⼀般的算法
+ 存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1
+ 删除困难。⼀个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为 0，可能会影响其他元素的判断。

### 缺点

缺点是有⼀定的误识别率和删除困难，bloom filter之所以能做到在时间和空间上的效率⽐较⾼，是因为牺牲了判断的准确率、删除的便利性

+ 存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。如果 bloom filter中存储的是⿊名单，那么可以通过建⽴⼀个白名单来存储可能会误判的元素。
+ 删除困难。⼀个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为 0，可能会影响其他元素的判断。

### 实现

+ 在使⽤bloom filter时，绕不过的两点是预估数据量n以及期望的误判率fpp
+  在实现bloom filter时，绕不过的两点就是hash函数的选取以及bit数组的⼤⼩。
+ 对于⼀个确定的场景，我们预估要存的数据量为n，期望的误判率为fpp，然后需要计算我们需要的Bit数 组的⼤⼩m，以及hash函数的个数k，并选择hash函数
+ 一个好的哈希函数要能近似等概率的将字符串映射到各个 Bit。选择k个不同的哈希函数⽐较麻烦，⼀种简单的⽅法是选择⼀个哈希函数，然后送入k个不同的参数。 

```java
//项目要导入guava的maven依赖
package com.tongji;


import com.google.common.hash.BloomFilter;
import com.google.common.hash.Funnels;

/**
 * 测试布隆过滤器(可用于redis缓存穿透)
 * @author tongji4m3
 */

public class TestBloomFilter {
    private static int total = 1000000;
    /*
    static <T> BloomFilter<T> create(Funnel<? super T> funnel， long expectedInsertions， double fpp， BloomFilter.Strategy strategy)
    funnel：数据类型(⼀般是调⽤Funnels⼯具类中的)
    expectedInsertions：期望插入的值的个数
    fpp 错误率(默认值为0.03)
    strategy 哈希算法

    numBits，表示存⼀百万个int类型数字，需要的位数为7298440，700多万位。理论上存⼀百万个
    数，⼀个int是4字节32位，需要481000000=3200万位。如果使⽤HashMap去存，按HashMap50%的
    存储效率，需要6400万位。可以看出BloomFilter的存储空间很⼩，只有HashMap的1/10左右

    错误率越⼤，所需空间和时间越⼩，错误率越⼩，所需空间和时间越⼤
     */
    private static BloomFilter<Integer> bloomFilter = BloomFilter.create(Funnels.integerFunnel()， total);

    public static void main(String[] args) {
        //初始化total条数据到过滤器里
        for (int i = 0; i < total; i++) {
            bloomFilter.put(i);
        }
        //匹配已经再过滤器中的值，看是否有匹配不上的
        //没有输出，说明只要放进去的，都能匹配上
        for (int i = 0; i < total; i++) {
            if (!bloomFilter.mightContain(i)) {
                System.out.println("有坏人逃脱啦~");
            }
        }

        //匹配不在过滤器中的10000个值，有多少匹配出来
        int count = 0;
        for (int i = total; i < total + 10000; i++) {
            if (bloomFilter.mightContain(i)) {
                ++count;
            }
        }
        //误伤数量: 320 错误率是0.03左右
        System.out.println("误伤数量: "+count);
    }
}
```

### 应用

#### 缓存击穿

数据库的id都是1开始然后自增的，那我知道你接⼝是通过id查询的，我就拿负数去查询，这个时候，会发现缓存里面没这个数据，我⼜去数据库查也没有，⼀个请求这样，100个，1000 个，10000个呢？你的DB基本上就扛不住了，如果在缓存里面加上这个，是不是就不存在了，你判断没这个数据就不去查了，直接return⼀个数据为空不就好了嘛。

+ 海量数据去重
+ 用于检索一个元素是否在一个集合中
+ 爬⾍过滤已抓到的url就不再抓，可⽤bloom filter过滤，只会使得爬虫系统错过少量的新页面
+ 垃圾邮件过滤。Bloom Filter只需要哈希表 1/8到 1/4 的大小
+ 海量数据去重：不断放入元素到集合中，检索一个元素是否在一个集合中，在则说明重复、推荐去重，即APP会把用户已经看过的内容去掉、能准确过滤掉用户已经看过的内容，那些用户没有看过的新内容，也会过滤掉极小一部分（误判）

