---
title: Redis设计机制
author: tongji4m3
top: true
cover: false
coverImg: /images/1.jpg
toc: true
mathjax: false
summary: 包括缓存（缓存穿透、缓存击穿、缓存雪崩）、过期键删除策略、RDB/AOF持久化等。
categories: Redis
tags:
  - 缓存
  - 持久化
  - 删除策略
abbrlink: '83265645'
date: 2020-11-14 00:00:00
---



# Redis简介

它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。

命令不区分大小写，而key区分大小写

Redis所有的数据结构都以唯一的key字符串作为名称，不同类型的数据结构的差异就在于value的结构不一样

所有数据结构都可以设置过期时间

## 基本认识

### 官方介绍

Remote Dictionary Service(远程词典服务)，是一个存储中间件

Redis采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的QPS（每秒内查询次数）。

Redis是一个开源的内存中的数据结构存储系统，它可以用作：**数据库、缓存和消息中间件**。

它支持多种类型的数据结构，如字符串（Strings），散列（Hash），列表（List），集合（Set），有序集合（Sorted Set或者是ZSet）与范围查询，Bitmaps，Hyperloglogs 和地理空间（Geospatial）索引半径查询。**其中常见的数据结构类型有：String、List、Set、Hash、ZSet这5种。**

Redis 内置了复制（Replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（Transactions） 和不同级别的磁盘持久化（Persistence），并通过 Redis哨兵（Sentinel）和自动分区（Cluster）提供高可用性（High Availability）。

Redis也提供了持久化的选项，这些选项可以让用户将自己的数据保存到磁盘上面进行存储。根据实际情况，可以每隔一定时间将数据集导出到磁盘（快照），或者追加到命令日志中（AOF只追加文件），他会在执行写命令时，将被执行的写命令复制到硬盘里面。您也可以关闭持久化功能，将Redis作为一个高效的网络的缓存数据功能使用。

### Redis为什么快

- redis是基于内存的，数据存在内存中，内存的读写速度非常快；它类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；
- 数据结构简单，对数据操作也简单，有高效的数据结构。底层多种数据结构支持不同的数据类型，支持 Redis 存储不同的数据
- 采用单线程，避免了不必要的上下文切换和竞争条件，不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
- redis使用I/O多路复用技术，可以处理并发的连接。非阻塞IO 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在IO上浪费一点时间。

## Redis和memcached的区别

+ Redis 支持复杂的数据结构，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作
+ Redis 提供主从同步机制，以及 Cluster 集群部署能力，能够提供高可用服务
+ 性能方面，Redis 只使用单核，而 Memcached 可以使用多核，所以平均每一个核上 Redis 在存储小数据时比 Memcached 性能更高。而在 100k 以上的数据中，Memcached 性能要高于 Redis，虽然 Redis 最近也在存储大数据的性能上进行优化，但是比起 Remcached，还是稍有逊色。
+ Redis ⽀持持久化，所以 Redis 不仅仅可以⽤作缓存，也可以⽤作 NoSQL 数据库。

## 为什么Redis是单线程的

这里我们一直在强调的单线程，只是在处理我们的网络请求的时候只有一个线程来处理，一个正式的Redis Server运行的时候肯定是不止一个线程的，这里需要大家明确的注意一下！例如Redis进行持久化的时候会以子进程或者子线程的方式执行

 单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程。

 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间

**1.官方答案**

因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。

**2.性能指标**

关于redis的性能，官方网站也有，普通笔记本轻松处理每秒几十万的请求。

**3.详细原因**

**1）不需要各种锁的性能消耗**

Redis的数据结构并不全是简单的Key-Value，还有list，hash等复杂的结构，这些结构有可能会进行很细粒度的操作，比如在很长的列表后面添加一个元素，在hash当中添加或者删除

一个对象。这些操作可能就需要加非常多的锁，导致的结果是同步开销大大增加。

总之，在单线程的情况下，就不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗。

**2）单线程多进程集群方案**

单线程的威力实际上非常强大，每核心效率也非常高，多线程自然是可以比单线程有更高的性能上限，但是在今天的计算环境中，即使是单机多线程的上限也往往不能满足需要了，需要进一步摸索的是多服务器集群化的方案，这些方案中多线程的技术照样是用不上的。

**所以单线程、多进程的集群不失为一个时髦的解决方案。**

**3）CPU消耗**

采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU。

但是如果CPU成为Redis瓶颈，或者不想让服务器其他CUP核闲置，那怎么办？

可以考虑多起几个Redis进程，Redis是key-value数据库，不是关系数据库，数据之间没有约束。只要客户端分清哪些key放在哪个Redis进程上就可以了。

## Redis单线程的优劣势

**单进程单线程优势**

1. 代码更清晰，处理逻辑更简单
2. 不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗
3. 不存在多进程或者多线程导致的切换而消耗CPU

**单进程单线程弊端**

1. 无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来完善；

## 为什么快

Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而  **I/O 多路复用** 就是为了解决这个问题而出现的。

redis的io模型主要是基于epoll实现的，不过它也提供了 select和kqueue的实现，默认采用epoll。

+ 优先选择时间复杂度为O(1)的IO复用函数作为底层实现，例如epoll
+ 以select系统调用为保底，时间复杂度O(N)
+ 基于react设计模式监听IO事件

多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。

**这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。**采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。

## 数据库

### 服务器中的数据库

```c
struct redisServer
{
	int dbnum;//服务器的数据库数量
	redisDb *db; //一个数组，保存着服务器中的所有数据库 默认16
}
```

### 切换数据库

每个Redis客户端都有个目标数据库，每当客户端执行数据库读写命令时，目标数据库就成为这些命令的操作对象.默认目标数据库为0号数据库

```c
typedef struct redisClient
{
	redisDb * db;//记录客户端当前使用的数据库
}redisClient;
```

### 数据库键空间

```c
typedef struct redisDb
{
	dict *dict;//数据库键空间，保存着数据库中的所有键值对
} redisDb;
```

键空间的键是一个字符串对象，值可以是字符串对象，列表对象，哈希表对象，集合对象，有序集合对象

所有针对数据库的操作，都是通过对键空间字典进行操作实现的

#### 添加新键

就是将新键值对添加到键空间字典里面

#### 读写键空间时的维护操作

+ 在读取一个键后(读写操作都要对键进行读取)，服务器会根据键是否存在来更新服务器的键空间命中次数
+ 在读取一个键后，会更新LRU时间，可以计算键的闲置时间
+ 在读取一个键若发现该键已过期，则会先删除过期键
+ 在对被监视的键进行修改后，会标记为脏，让事务程序注意该键已经被修改

# 缓存

## 缓存穿透

查询某个Key对应的数据，Redis缓存中没有相应的数据，则直接到数据库中查询。数据库中也不存在要查询的数据，则数据库会返回空，而Redis也不会缓存这个空结果。这就造成每次通过这样的Key去查询数据都会直接到数据库中查询，Redis不会缓存空结果。这就造成了缓存穿透的问题。

一些恶意的请求会故意查询不存在的 key，请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。

### 解决

1. 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。
2. 如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
3. 根据明显错误的key在逻辑层就就行验证。
4. 分析用户行为，是否为故意请求或者爬虫、攻击者。针对用户访问做限制。

## 缓存击穿

缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，好像蛮力击穿一样。

击穿和穿透不同，穿透的意思是想法绕过redis去使得数据库崩掉。而击穿你可以理解为正面刚击穿，这种通常为大量并发对一个key进行大规模的读写操作。**这个key在缓存失效期间大量请求数据库**，对数据库造成太大压力使得数据库崩掉。就比如在秒杀场景下10000块钱的mac和100块的mac这个100块的那个订单肯定会被抢到爆，不断的请求(当然具体秒杀有自己处理方式这里只是举个例子)。所以缓存击穿就是针对某个常用key大量请求导致数据库崩溃。

### 解决

#### 使用互斥锁

在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。

在访问key之前，采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key。

```java
public String get(key) {
      String value = redis.get(key);
      if (value == null) 
      { 
          //代表缓存值过期
          //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db
		  if (redis.setnx(key_mutex， 1， 3 * 60) == 1) 
          {  
              //代表设置成功
              value = db.get(key);
              redis.set(key， value， expire_secs);
              redis.del(key_mutex);
          } 
          else 
          {  //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可
              sleep(50);
              get(key);  //重试
          }
      } 
    else 
    {
        return value;      
    }
 }
```

#### 热点key永不过期

## 缓存雪崩

大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。

### 解决

- 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个 key 只允许一个线程查询数据和写缓存，其他线程等待。
- 做二级缓存，A1 为原始缓存，A2 为拷贝缓存，A1 失效时，可以访问 A2，A1 缓存失效时间设置为短期，A2 设置为长期
- 可以给缓存设置过期时间时加上一个随机值时间，使得每个key的过期时间分布开来，不会集中在同一时刻失效。
- 热点数据可以考虑不失效

# 过期键删除策略

## 过期键实现

### 设置过期时间

1. EXPIRE 设置过期时间，单位为秒
2. PEXPIRE 设置过期时间，单位为毫秒
3. EXPIREAT 设置过期时间为秒数时间戳
4. PEXPIREAT 设置过期时间为毫秒数时间戳

最后都是转换为PEXPIREAT来执行的

### 保存过期时间

```c
typedef struct redisDb
{
	dict *dict;//数据库键空间，保存着数据库中的所有键值对
	dict *expires;//保存了数据库中所有键的过期时间，过期字典
	//key是一个指针，指向键空间某个键
	//value为long long类型的过期时间，一个毫秒精度的UNIX时间戳
} redisDb;
```

键空间的键和过期字典的键都指向同一个键对象，不会出现任何重复对象，也不会浪费任何空间

```python
def PEXPIREAT(key，expire_time_in_ms)
{
 	#如果给定的键不存在键空间，那么不能设置过期时间
    if key not in redisDb.dict:
    	return 0
    #在过期字典中关联键和过期时间
    redisDb.expires[key] = expire_time_in_ms
    # 过期时间设置成功
    return 1
}
```

### 移除过期时间

```python
def PERSIST(key):
    #如果给定的键不存在或没设置过期时间，那么直接返回
     if key not in redisDb.expires:
    	return 0
    #移除过期字典中给定键的键值对关联
    redisDb.expires.remove(key)
    #移除成功
    return 1
```

### 计算并返回剩余生存时间

```python
def PTTL(key):
    #如果给定的键不存在数据库
    if key not in redisDb.dict:
    	return -2
    #尝试获取过期时间
    #没有则为None
    expire_time_in_ms=redisDb.expires.get(key)
    
    if expire_time_in_ms is None:
        return -1
    # 获取当前时间时间戳
    now_ms=get_current_unix_timestamp_in_ms()
    return (expire_time_in_ms - now_ms)
```

```python
def TTL(key):
    ttl_in_ms = PTTL(key)
    if ttl_in_ms<0:
        //处理为-2，-1的异常情况
        return ttl_in_ms
    else:
        #将毫秒转为秒
        return ms_to_sec(ttl_in_ms)
    
```

### 过期键的判断

```python
def is_expired(key):
    #尝试获取过期时间
    #没有则为None
    expire_time_in_ms=redisDb.expires.get(key)
    
    if expire_time_in_ms is None:
        return False
    
    # 获取当前时间时间戳
    now_ms=get_current_unix_timestamp_in_ms()
    
    if  now_ms>expire_time_in_ms:
        return True # 已过期
    else:
        return False
```

## 定时删除

- 在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作

- 可以保证过期键会尽可能快地被删除，并释放过期键所占用的内存

- 对CPU时间最不友好，在内存不紧张而CPU非常紧张的情况下，将CPU时间用在删除和当前任务无关的过期键上，对服务器的响应时间和吞吐量造成影响

- 不太现实


## 惰性删除

- 每次取出键都会检查是否过期，过期则删除

- 只有在取出键时才会对键进行过期检查，对CPU时间最友好

- 对内存最不友好：如果一个键已过期，而这个键又仍然保留在数据库中，那么只要这个过期键不被删除，他所占用的内存就不会释放。

- 会导致内存泄漏，无用的垃圾数据占用了大量内存。如日志，当不再使用时，会大量积压在数据库，用户以为自动删除了，其实还存在，则它们不会被删除，所占用的内存就不会释放。


## 定期删除

- 每隔一段时间进行检查，删除里面的过期键
- 通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响；定期删除策略有效减少了因为过期键而带来的内存浪费。是前两种的整合与折中。
- 必须合理地设置删除操作的执行时间和执行效率：太频繁或执行时间太长会退化为定时删除策略，反之则出现浪费内存的情况


## Redis过期键删除策略

配合使用**惰性删除**和**定期删除**两种

### 惰性删除策略的实现

所有读写数据库的Redis命令在执行之前都会调用expireIfNeeded函数对输入键进行检查，如果输入键已过期，则将输入键从数据库中删除

采用expireIfNeeded函数，如果过期则将键删除。就像过滤器，在命令真正执行前，过滤掉过期的输入键，避免命令接触到过期键

所以每个命令的实现函数必须能同时处理键存在和不存在两种情况

![image-20210207104150550](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207104150550.png)

![image-20210207104206293](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207104206293.png)

### 定期删除策略实现

每当Redis服务器周期性操作serverCron函数执行时，activeExpireCycle函数就会被调用，它在规定的时间内，分多次遍历服务器中的各个数据库，从数据库的expires字典中随机检查一部分键的过期时间，并删除其中的过期键

```python
# coding=utf-8
# 默认每次检查的数据库数量
DEFAULT_DB_NUMBERS = 16

# 默认每个数据库检查的键数量
DEFAULT_KEY_NUMBERS = 20

# 全局变量，记录检查进度
# 如果当前的activeExpireCycle函数在遍历10号数据库时返回了，那么下次activeExpireCycle函数时，将从11号数据库开始查找并删除过期键
current_db = 0

# 函数每次运行时，都从一定数量的数据库中取出一定数量的随机键进行检查，并删除其中的过期键
def activeExpireCycle():
    # 初始化要检查的数据库数量
    # 以服务器的数据库数量为主
    if serer.dbnum < DEFAULT_DB_NUMBERS:
        db_numbers = serer.dbnum
    else:
        db_numbers = DEFAULT_DB_NUMBERS

    #遍历每个数据库
    for i in range(db_numbers):
        #如果current_db=服务器的数据库数量
        #则表示已经遍历了服务器的所有数据库一次
        #将current_db=重置为0，开始新一轮
        if current_db==server.dbnum:
            current_db=0
        
        #获取当前要处理的数据库
        redisDb=server.db[current_db]
        
        #指向下一个要处理的数据库
        current_db+=1
        
        #检查数据库的键
        for j in range(DEFAULT_KEY_NUMBERS):
            #如果数据库中没有一个键带有过期时间，则跳过该数据库
            if redisDb.expires.size()==0:
                break
            
            #随机获取一个带过期时间的键
            key_with_ttl=redisDb.expires.get_random_key()
            
            if is_expired(key_with_ttl):
                delete_key(key_with_ttl)
                
            # 已到达时间上限，停止处理
            if reach_time_limit():
                return 
```

# 持久化

## RDB持久化

### 创建

**SAVE指令**会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求，所以当Save命令正在执行时，客户端发送的所有命令请求都会被阻塞

**BGSAVE命令**会派生出一个子进程，由它负责创建RDB文件，服务器进程(父进程)继续处理命令请求。



1、在BGSAVE命令执行期间，客户端发送的SAVE命令会被服务器拒绝。服务器禁止SAVE与BGSAVE同时执行是为了避免父进程和子进程同时指向两个rdbSave调用，防止产生竞争条件。

2、同样的道理，在BGSAVE执行期间，客户端的BGSAVE命令也会被服务器拒绝。

3、另外，对于AOF持久化命令BGREWRITEAOF与BGSAVE也同样是互斥关系，如果BGSAVE正在执行，则BGREWRITEAOF命令会被延迟到BGSAVE执行完毕之后；而BGREWRITEAOF命令执行时，服务器会拒绝BGSAVE命令的执行。

4、而事实上，因为BGREWRITEAOF命令与BGSAVE两个命令的实际工作都是由子进程执行，所以这两个命令在操作方面并没有冲突的地方，不能同时执行只是性能方面的考虑--并发处两个子进程，并且这两个子进程同时对磁盘进行大量读写。

```python
def SAVE():
	#创建RDB文件
	rdbSave（）
	
def BGSAVE():
	# 创建子进程
	pid=fork()
	
	if pid == 0:
		# 子进程负责创建RDB文件
		rdbSave（）
		# 完成之后向父进程发送信号
		signal_parent()
	elif pid>0:
		# 父进程继续处理命令请求，并通过轮询等待子进程的信号
		handle_request_and_wait_signal()
	else:
		# 处理出错情况
		handle_fork_error()
```

### 载入

- RDB文件的载入工作是服务器启动时自动进行的，只要Redis服务器在启动时检测到RDB文件存在，就会自动载入RDB文件
- 如果服务器开启了AOF持久化功能，则优先使用AOF文件还原数据库状态
- 只有未开启AOF持久化功能，才会使用RDB文件还原数据库状态
- 服务器在载入RDB文件时会一直处于阻塞状态，直到载入工作完成

### 自动间隔性保存

服务器每隔一段时间自动执行一次BGSAVE命令，可以设置多个保存条件，只要任意一个条件被满足，服务器就会执行BGSAVE指令

```c
save 900 1
save 300 10
save 60 10000

服务器在900秒内进行了至少1次修改
服务器在300秒内进行了至少10次修改
服务器在60秒内进行了至少10000次修改
```

### 设置保存条件

服务器程序根据save选项（可通过配置文件设置）所设置的保存条件，设置服务器状态的redisServer结构的saveparams属性

```c
struct redisServer
{
	struct saveparam * saveparams;
	long long dirty; //距离上一次成功执行BGSAVE之后，进行修改的次数
	time_t lastsave; //上一次成功执行BGSAVE的时间
};

struct saveparam
{
	time_t seconds;
	int changes;
}
```

### 检查保存条件是否满足

服务器周期性操作函数serverCron()默认每隔100ms执行一次

其中一项工作就是检查save选项所设置的保存条件是否已经满足

如果满足，则执行BGSAVE（）

```python
def serverCron():
	# 遍历所有保存条件
	for saveparam in server.saveparams:
		save_interval=unixtime_now() - server.lastsave
		
		#如果数据库状态的修改次数超过条件所设置的次数
		#并且距离上次保存的时间超过条件所设置的时间
		#那么执行保存操作
		if server.dirty >= saveparam.changes and save_interval>saveparam.seconds:
			BGSAVE()
```

### RDB文件结构

#### 概览

1. REDIS，通过这五个字符，程序可以在载入文件时，快速检查所载入的文件是否是RDB文件
2. db_version，记录了版本号
3. databases，包含任意个数据库以及他们的键值对数据。
4. EOF，标志着RDB文件正文内容的结束
5. check_sum，校验和，检查RDB文件是否有出错或损坏的情况。服务器在载入RDB文件时，会将载入数据所计算出的校验和与check_sum进行比对，已发行RDB文件是否损坏

#### databases

每个非空数据库保存三部分：

1. SELECTDB 常量，说明接下来会读取一个数据库号码
2. db_number，读入后，调用SELECT指令，进行数据库切换，使得之后读入的键值对可以载入到正确的数据库之中
3. key_value_pairs，保存了数据库中的所有键值对数据。包含过期时间。

#### key_value_pairs

1. TYPE记录了value的类型，代表了一种对象类型或底层编码。程序根据TYPE的值决定如何读入和解释value的数据
2. key总是一个字符串对象
3. value根据TYPE的指令保存相应类型的内容
4. EXPIRETIME_MS常量，代表之后会读取一个以毫秒为单位的过期时间
5. ms，保存键值对的过期时间，以毫秒为单位的UNIX时间戳



## AOF持久化

### 简介

- AOF（Append Only File)
- 通过保存`Redis`服务器所执行的写命令来记录数据库状态的
- 被写入AOF文件的所有命令都是以Redis的命令请求协议格式（纯文本）保存的。
- 服务器启动时，可以通过载入和执行`AOF文件`中保存的命令来还原服务器关闭之前的数据库状态


### AOF持久化的实现

#### 命令追加

服务器在执行完一个写命令后，会将被执行的写命令追加到服务器状态的`aof_buf`缓冲区的末尾:

```c
struct redisServer
{
	// AOF缓冲区
	sds aof_buf;
}
```

#### AOF文件的写入与同步

服务器进程是一个事件循环，循环中的文件事件负责接收客户端的命令请求，以及向客户端发送命令回复。时间事件负责执行像serverCron函数这样需要定时运行的函数

```python
def eventLoop()
{
	while True:
		#处理文件事件，接收命令请求以及发送命令回复
		#处理命令请求时可能会有新内容加入到aof_buf缓冲区中
		processFileEvents()
		
		#处理时间事件
		processTimeEvents()
		
		#考虑是否要将aof_buf缓冲区中的内容写入和保存到AOF文件里面
		flushAppendOnlyFile()
}
```

**写入**：在现代操作系统中，当数据写入到文件中时，会调用write函数。操作系统会将写入数据暂时保存在一个内存缓存区中，等到缓冲区空间满的时候，才真正将缓冲区中的数据写入到磁盘中。

**同步**：同时系统也提供了同步函数（例如fsync)，它可以强制让操作系统立即将缓冲区中的数据写入到磁盘中。



在每个事件循环都会调用flushAppendOnlyFile函数，flushAppendOnlyFile函数的行为由**appendfsync**的值决定：

**always**：服务器在每个事件循环都要将aof_buf缓冲区中的所有内容写入到AOF文件中，并同步AOF文件（把aof_buf数据写入并同步到AOF文件中）

**everysec**：服务器在每个事件循环都要将aof_buf缓冲区中的所有内容写入到AOF文件中(先写入)，并且每隔一秒就在子线程中对AOF文件进行一次同步(每隔一秒同步)。

**no**：服务器在每个事件循环都要将aof_buf缓冲区中的所有内容写入到AOF文件中(先写入)，至于什么时候同步，由操作系统控制（不知道啥时候同步）。在该模式下的flushAppendOnlyFile的调用不需要同步执行。



上述配置的值，直接决定服务器的效率与安全性，当always时，安全性最高，但是效率最低；no时效率最高，安全性最低；everysec居中：从效率上来讲，everysec模式足够快，并且就算出现了故障停机，数据库也只丢失一秒钟的命令数据。系统默认配置是everysec。

### AOF文件的载入与数据还原

只要读入并重新执行一遍`AOF文件`里面保存的写命令，就可以还原服务器关闭之前的数据库状态

1. 创建一个不带网络连接的伪客户端
2. 从AOF文件中分析并读取出一条写命令
3. 使用伪客户端执行被读出的写命令
4. 一直执行2，3直到AOF文件中的所有写命令都被处理完毕

![image-20210207113554356](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207113554356.png)

### AOF重写

为了解决AOF文件体积膨胀的问题，Redis提供了AOF文件重写(rewrite)功能。

服务器创建一个新的AOF文件来**替代**现有的AOF文件，新旧两个AOF文件所保存的数据库状态相同，但是新的AOF文件不会包含任何浪费空间的冗余命令

### AOF文件重写的实现

不需要对现有的AOF文件进行操作，是通过读取服务器当前的数据库状态来实现的

首先从数据库中读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令，这就是AOF重写功能的实现原理。

```python
def aof_rewrite(new_aof_file_name):
	#创建新的aof文件
	f=create_file(new_aof_file_name)
	#遍历数据库
	for db in redisServer.db:
		#忽略空数据库
		if db.is_empty():continue
		
		#写入SELECT命令，指定数据库号码
		f.write_command("SELECT"+db.id)
		
		#遍历数据库中所有键
		for key in db:
			#忽略过期的键
			if key.is_expired():continue
			
			#根据键的类型对键进行重写
			if key.type == String:
				rewrite_string(key)
			elif key.type == List:
				rewrite_list(key)
			elif key.type == Hash:
				rewrite_hash(key)
            elif key.type == Set:
				rewrite_set(key)
            elif key.type == SortedSet:
				rewrite_sortedSet(key)
				
			# 如果键带有过期时间，过期时间也要重写
			if key.have_expired_time():
				rewrite_expired_time(key)
	#写入完毕，关闭文件			
	f.close()
	
def rewrite_string(key):
	#使用GET命令获取字符串的值
	value=GET(key)
	#使用SET命令重写字符串键
	f.write_command(SET，key，value)
	
def rewrite_expired_time(key):
	#获取毫秒精度的键过期时间戳
	timestamp=get_expired_time_in_unixstamp(key)
	#使用PEXPIREAT命令重写键的过期时间
	f.write_command(PEXPIREAT，key，timestamp)
```



### AOF后台重写

因为aof_rewrite函数会进行大量的写入操作，所以调用这个函数的线程将被长时间阻塞

因为Redis服务器使用单个线程来处理命令请求，所以如果由服务器直接调用aof_rewrite函数的话，那么在重写AOF文件期间，服务器将无法处理客户端发来的命令请求。

所以决定将AOF重写程序放到**子进程**中执行

+ 子进程在进行AOF重写期间，服务器进程可以进行处理命令请求
+ 子进程带有服务器进程的**数据副本**，使用子进程而不是线程，可以在避免使用锁的情况下，保证数据的安全性

但是有可能导致当前数据库状态和重写后的AOF文件所保存的数据库**状态不一致**



#### AOF重写缓冲区

为了解决数据不一致问题，Redis服务器设置了一个AOF重写缓冲区，这个缓冲区在服务器创建子进程之后开始使用，当Redis服务器执行完一个写命令之后，会同时将这个命令发送给**AOF缓冲区和AOF重写缓冲区**

![image-20210207114138147](https://tongji2021.oss-cn-shanghai.aliyuncs.com/img/image-20210207114138147.png)

在子进程执行AOF重写期间，服务器进程执行:

1. 执行客户端发来的指令
2. 将执行后的写命令追加到AOF缓冲区
3. 将执行后的写命令追加到AOF重写缓冲区



这样一来可以**保证**

- AOF缓冲区的内容会定期被写入和同步到AOF文件，对现有AOF文件的处理工作会如常进行。
- 从创建子进程开始，服务器执行的所有写命都会被记录到AOF重写缓冲区里面。



当子进程完成AOF重写工作之后，它  会向父进程发送一个信号，父进程在接到该信号之后，会调用一个信号处理函数，并执行以下工作：

- 将AOF重写缓冲区中的所有内容重写到新AOF文件中，这时新AOF文件保存的数据库状态将**和服务器当前的数据库状态一致**。
- 对新的AOF文件进行改名，原子地(atomic)覆盖现有地AOF文件，完成**新旧两个AOF文件地替换**。

这个信号处理函数执行完毕后，父进程可以继续像往常一样接收命令请求了



在整个AOF后台重写过程中，只有**信号处理函数执行时会对服务器进程（父进程）造成阻塞**，在其他时候，AOF后台重写都不会阻塞父进程，这将AOF重写对服务器性能造成的影响降到了最低。

# 分布式锁

## 理解

在单机环境中，应用是在同一进程下的，只需要保证单进程多线程环境中的线程安全性，通过 JAVA 提供的 volatile、ReentrantLock、synchronized 以及 concurrent 并发包下一些线程安全的类等就可以做到。

一个应用往往会部署在多台机器上（多节点），在某些场景中，多个进程必须以互斥的方式独占共享资源。因此需要使用分布式锁



分布式锁，顾名思义，就是分布式项目开发中用到的锁，可以用来控制分布式系统之间同步访问共享资源，一般来说，分布式锁需要满足的特性有这么几点：

1、互斥性：在任何时刻，对于同一条数据，只有一台应用可以获取到分布式锁；

2、高可用性：在分布式场景下，一小部分服务器宕机不影响正常使用，这种情况就需要将提供分布式锁的服务以集群的方式部署；

3、防止锁超时：如果客户端没有主动释放锁，服务器会在一段时间之后自动释放锁，防止客户端宕机或者网络不可达时产生死锁；

4、独占性：加锁解锁必须由同一台服务器进行，也就是锁的持有者才可以释放锁，不能出现你加的锁，别人给你解锁了；

## setnx（set if not exists)

```
SETNX key value
```

SET if Not eXists(如果不存在，则 SET)

命令在设置成功时返回 1 ，设置失败时返回 0 。

用来实现Redis锁机制，一个进程进来占坑，用完后再调用del指令释放坑

只在键 key 不存在的情况下，将键 key 的值设置为 value 。若键 key 已经存在， 则 SETNX 命令不做任何动作。

**中间代码异常**

如果逻辑执行到中间出现异常，可能导致del指令没有被调用，就会陷入死锁，锁永远得不到释放

可以再拿到锁以后再给锁加上一个过期时间，比如5s，这样即使中间出现异常也可以保证5s后锁会自动释放

```redis
setnx tongji4m3 true

expire tongji4m3 5

del tongji4m3
```

**expire异常**

如果在setnx和expire之间服务器出现问题，导致expire得不到执行，也会死锁

根源在于setnx和expire不是一条原子指令，但又不能用事务解决，因为expire依赖与setnx的执行结果，如果setnx没抢到锁，expire是不应该执行的，而事务没有if-else分支逻辑

Redis支持set指令的扩展参数，使得setnx和expire指令可以一起执行，形成原子指令

```
SETEX key seconds value

SET key value [EX seconds] [PX milliseconds] [NX|XX]
set tongji4m3 true ex 5 nx
NX:只在键不存在时， 才对键进行设置操作。
XX:只在键已经存在时， 才对键进行设置操作。
```

将值 `value` 关联到 `key` ，并将 `key` 的生存时间设为 `seconds` (以秒为单位)。

如果 `key` 已经存在，`setex`命令将覆写旧值。

有小伙伴肯定会疑惑万一set value 成功 set time失败，那不就傻了么，这啊Redis官网想到了。

`setex`是一个原子性(atomic)操作，关联值和设置生存时间两个动作会在同一时间内完成。

单机加锁或synchronized就够了

但如果线程挂了,那锁就一直在那无法得到释放，后面的线程也永远得不到锁，又死锁了。

setex设置一个过期时间，就算线程1挂了，也会在失效时间到了，自动释放。

**超时问题**

如果在加锁和释放锁之间的逻辑执行得太长，以至于超出了锁的超时限制，会导致第一个线程持有的锁过期了而临界区的逻辑还没执行完

Redis分布式锁不能用于较长时间的任务

将set指令的value参数设置为随机数，释放锁时先匹配随机数是否一致，然后再删除key，确保当前线程持有的锁不会被其他线程释放，除非这个锁是因为过期了而被服务器自己释放的

但是匹配value和删除key不是一个原子操作，需要要Lua脚本处理，他保证多个指令的原子性执行

**可重入性**

线程在持有锁的情况下再次请求加锁，如果一个锁支持同一个线程的多次加锁，就是可重入锁

分布式锁要支持可重入，则要使用线程的Threadlocal变量存储当前持有锁的计数

### 怎么释放锁

释放锁的命令就简单了，直接删除key就行，但我们前面说了，因为分布式锁必须由锁的持有者自己释放，所以我们必须先确保当前释放锁的线程是持有者，没问题了再删除，这样一来，就变成两个步骤了，似乎又违背了原子性了，怎么办呢？

不慌，我们可以用lua脚本把两步操作做拼装

## redisson

redisson的锁，就实现了可重入

```java
ThreadPoolExecutor threadPoolExecutor =
        new ThreadPoolExecutor(inventory, inventory, 10L, SECONDS, linkedBlockingQueue);
long start = System.currentTimeMillis();
Config config = new Config();
config.useSingleServer().setAddress("redis://127.0.0.1:6379");
final RedissonClient client = Redisson.create(config);
final RLock lock = client.getLock("lock1");

for (int i = 0; i <= NUM; i++) {
    threadPoolExecutor.execute(new Runnable() {
        public void run() {
            lock.lock();
            inventory--;
            System.out.println(inventory);
            lock.unlock();
        }
    });
}
long end = System.currentTimeMillis();
System.out.println("执行线程数:" + NUM + "   总耗时:" + (end - start) + "  库存数为:" + inventory);
```


### 初始化

```java
public RLock getLock(String name) {
    return new RedissonLock(connectionManager.getCommandExecutor(), name);
}

public RedissonLock(CommandAsyncExecutor commandExecutor, String name) {
    super(commandExecutor, name);
    //命令执行器
    this.commandExecutor = commandExecutor;
    //UUID字符串
    this.id = commandExecutor.getConnectionManager().getId();
    //内部锁过期时间
    this.internalLockLeaseTime = commandExecutor.
                getConnectionManager().getCfg().getLockWatchdogTimeout();
    this.entryName = id + ":" + name;
```

### 加锁

```java
public void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException {
    
    //当前线程ID
    long threadId = Thread.currentThread().getId();
    //尝试获取锁
    Long ttl = tryAcquire(leaseTime, unit, threadId);
    // 如果ttl为空，则证明获取锁成功
    if (ttl == null) {
        return;
    }
    //如果获取锁失败，则订阅到对应这个锁的channel
    RFuture<RedissonLockEntry> future = subscribe(threadId);
    commandExecutor.syncSubscription(future);

    try {
        while (true) {
            //再次尝试获取锁
            ttl = tryAcquire(leaseTime, unit, threadId);
            //ttl为空，说明成功获取锁，返回
            if (ttl == null) {
                break;
            }
            //ttl大于0 则等待ttl时间后继续尝试获取
            if (ttl >= 0) {
                getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS);
            } else {
                getEntry(threadId).getLatch().acquire();
            }
        }
    } finally {
        //取消对channel的订阅
        unsubscribe(future, threadId);
    }
    //get(lockAsync(leaseTime, unit));
}
```

### 获取锁

```java
private <T> RFuture<Long> tryAcquireAsync(long leaseTime, TimeUnit unit, final long threadId) {

    //如果带有过期时间，则按照普通方式获取锁
    if (leaseTime != -1) {
        return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG);
    }
    
    //先按照30秒的过期时间来执行获取锁的方法
    RFuture<Long> ttlRemainingFuture = tryLockInnerAsync(
        commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(),
        TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);
        
    //如果还持有这个锁，则开启定时任务不断刷新该锁的过期时间
    ttlRemainingFuture.addListener(new FutureListener<Long>() {
        @Override
        public void operationComplete(Future<Long> future) throws Exception {
            if (!future.isSuccess()) {
                return;
            }

            Long ttlRemaining = future.getNow();
            // lock acquired
            if (ttlRemaining == null) {
                scheduleExpirationRenewal(threadId);
            }
        }
    });
    return ttlRemainingFuture;
}
```

### 底层加锁逻辑

你可能会想这么多操作，在一起不是原子性不还是有问题么？

大佬们肯定想得到呀，所以还是LUA，他使用了Hash的数据结构。

主要是判断锁是否存在，存在就设置过期时间，如果锁已经存在了，那对比一下线程，线程是一个那就证明可以重入，锁在了，但是不是当前线程，证明别人还没释放，那就把剩余时间返回，加锁失败。

```java
<T> RFuture<T> tryLockInnerAsync(long leaseTime, TimeUnit unit,     
                            long threadId, RedisStrictCommand<T> command) {

        //过期时间
        internalLockLeaseTime = unit.toMillis(leaseTime);

        return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,
                  //如果锁不存在，则通过hset设置它的值，并设置过期时间
                  "if (redis.call('exists', KEYS[1]) == 0) then " +
                      "redis.call('hset', KEYS[1], ARGV[2], 1); " +
                      "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                      "return nil; " +
                  "end; " +
                  //如果锁已存在，并且锁的是当前线程，则通过hincrby给数值递增1
                  "if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then " +
                      "redis.call('hincrby', KEYS[1], ARGV[2], 1); " +
                      "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                      "return nil; " +
                  "end; " +
                  //如果锁已存在，但并非本线程，则返回过期时间ttl
                  "return redis.call('pttl', KEYS[1]);",
        Collections.<Object>singletonList(getName()), 
                internalLockLeaseTime, getLockName(threadId));
    }
```



### 解锁

锁的释放主要是publish释放锁的信息，然后做校验，一样会判断是否当前线程，成功就释放锁，还有个**hincrby**递减的操作，锁的值大于0说明是可重入锁，那就刷新过期时间。

如果值小于0了，那删掉Key释放锁。

是不是又和AQS很像了？

AQS就是通过一个volatile修饰status去看锁的状态，也会看数值判断是否是可重入的。



```java
public RFuture<Void> unlockAsync(final long threadId) {
    final RPromise<Void> result = new RedissonPromise<Void>();
    
    //解锁方法
    RFuture<Boolean> future = unlockInnerAsync(threadId);

    future.addListener(new FutureListener<Boolean>() {
        @Override
        public void operationComplete(Future<Boolean> future) throws Exception {
            if (!future.isSuccess()) {
                cancelExpirationRenewal(threadId);
                result.tryFailure(future.cause());
                return;
            }
            //获取返回值
            Boolean opStatus = future.getNow();
            //如果返回空，则证明解锁的线程和当前锁不是同一个线程，抛出异常
            if (opStatus == null) {
                IllegalMonitorStateException cause = 
                    new IllegalMonitorStateException("
                        attempt to unlock lock, not locked by current thread by node id: "
                        + id + " thread-id: " + threadId);
                result.tryFailure(cause);
                return;
            }
            //解锁成功，取消刷新过期时间的那个定时任务
            if (opStatus) {
                cancelExpirationRenewal(null);
            }
            result.trySuccess(null);
        }
    });

    return result;
}


protected RFuture<Boolean> unlockInnerAsync(long threadId) {
    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, EVAL,
    
            //如果锁已经不存在， 发布锁释放的消息
            "if (redis.call('exists', KEYS[1]) == 0) then " +
                "redis.call('publish', KEYS[2], ARGV[1]); " +
                "return 1; " +
            "end;" +
            //如果释放锁的线程和已存在锁的线程不是同一个线程，返回null
            "if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then " +
                "return nil;" +
            "end; " +
            //通过hincrby递减1的方式，释放一次锁
            //若剩余次数大于0 ，则刷新过期时间
            "local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); " +
            "if (counter > 0) then " +
                "redis.call('pexpire', KEYS[1], ARGV[2]); " +
                "return 0; " +
            //否则证明锁已经释放，删除key并发布锁释放的消息
            "else " +
                "redis.call('del', KEYS[1]); " +
                "redis.call('publish', KEYS[2], ARGV[1]); " +
                "return 1; "+
            "end; " +
            "return nil;",
    Arrays.<Object>asList(getName(), getChannelName()), 
        LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));

}
```

