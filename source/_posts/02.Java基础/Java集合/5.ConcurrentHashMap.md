---
title: ConcurrentHashMap
author: tongji4m3
top: false
cover: false
coverImg: /images/1.jpg
toc: true
mathjax: false
summary: Java集合ConcurrentHashMap，包括底层实现、JDK7的实现结构、线程安全实现等
categories: Java集合
tags:
  - 集合
  - ConcurrentHashMap
  - 源码
abbrlink: cdf574e9
date: 2020-12-26 00:00:00
---







# JDK7的ConcurrentHashMap

+ 首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。
+ 由一个Segment数组和多个HashEntry组成

## Segment

+ Segment 是一种可重入的锁 ReentrantLock。
+ Segment数组的意义就是将一个大的table分割成多个小的table来进行加锁
+ 每一个Segment元素存储的是HashEntry数组+链表
+ 可以把每个 Segment 看成是一个小的 HashMap，其内部结构和 HashMap 是一模一样的
+ 当对某个 Segment 加锁时，并不会影响到其他 Segment 的读写。每个 Segment 内部自己操作自己的数据。

## HashEntry

+ 每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。

+ 每个 HashEntry 是一个链表结构的元素

    

# ConcurrentHashMap

+ 抛弃了Segment分段锁机制，利用CAS+Synchronized来保证并发更新的安全，底层采用数组+链表+红黑树的存储结构。
+ 在构造函数中只会初始化sizeCtl值，并不会直接初始化table，而是延缓到第一次put操作。
+ ConcurrentHashMap不允许key或value为null值

# 结构

```java
//    记录容器的容量大小，通过CAS更新
    private transient volatile long baseCount;

    /**
     * 这个sizeCtl是volatile的，那么他是线程可见的
     * 当sizeCtl小于0说明有多个线程正则等待扩容结果，参考transfer函数
     * sizeCtl等于0是默认值，大于0是扩容的阀值
     */
    private transient volatile int sizeCtl;
/**
 * 自旋锁 （锁定通过 CAS） 在调整大小和/或创建 CounterCells 时使用。
 * 在CounterCell类更新value中会使用，功能类似显示锁和内置锁，性能更好
 */
private transient volatile int cellsBusy;
```

## sizeCtl

+ 控制标识符，在不同的地方有不同用途，而且它的取值不同，也代表不同的含义
+ 负数代表正在进行初始化或扩容操作
+ -1代表正在初始化
+ -N 表示有N-1个线程正在进行扩容操作
+ 正数或0代表hash表还没有被初始化，这个数值表示初始化或下一次进行扩容的大小，类似于扩容阈值loadfactor,它的值始终是当前ConcurrentHashMap容量的0.75倍



## Node

+ 最核心的内部类，它包装了key-value键值对，所有插入ConcurrentHashMap的数据都包装在这里面。
+ 它对value和next属性设置了volatile同步锁
+ 它不允许调用setValue方法直接改变Node的value域
+ 它增加了find方法辅助map.get()方法。

## TreeNode

+ 当链表长度过长的时候，会转换为TreeNode。
+ 但是与HashMap不相同的是，它并不是直接转换为红黑树，而是把这些结点包装成TreeNode放在TreeBin对象中，由TreeBin完成对红黑树的包装。
+ TreeNode集成自Node类，而并非HashMap中的集成自LinkedHashMap.Entry<K,V>类，也就是说TreeNode带有next指针，这样做的目的是方便基于TreeBin的访问。

## TreeBin

+ 包装TreeNode节点。它代替了TreeNode的根节点
+ ConcurrentHashMap“数组”中，存放TreeBin对象
+ 带有读写锁。

## ForwardingNode

+ 一个用于连接两个table的节点类。它包含一个nextTable指针，用于指向下一张表。
+ 这个节点的key value next指针全部为null，它的hash值为-1.
+ 这里面定义的find的方法是从nextTable里进行查询节点，而不是以自身为头节点进行查找
+ 只有table发生扩容的时候，ForwardingNode才会发挥作用，作为一个占位符放在table中表示当前节点为null或则已经被移动。

## table

+ 默认为null，初始化发生在第一次插入操作，默认大小为16的数组，用来存储Node节点数据，扩容时大小总是2的幂次方。

## nextTable

+ 默认为null，扩容时新生成的数组，其大小为原数组的两倍。

# 线程安全

## Unsafe与CAS

+ 大量使用了U.compareAndSwapXXX的方法，这个方法是利用一个CAS算法实现无锁化的修改值的操作，他可以大大降低锁代理的性能消耗。
+ unsafe静态块控制了一些属性的修改工作，比如最常用的SIZECTL
+ 这个算法的基本思想就是不断地去比较当前内存中的变量值与你指定的一个变量值是否相等，如果相等，则接受你指定的修改的值，否则拒绝你的操作。因为当前线程中的值已经不是最新的值，你的修改很可能会覆盖掉其他线程修改的结果。
+ 利用CAS进行无锁操作，可以大大提高性能。
+ 大量应用来的CAS方法进行变量、属性的修改工作。

## 三个辅助方法

```java
@SuppressWarnings("unchecked")
//获得在i位置上的Node节点
static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
    return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);
}

/*
 *计算偏移量(long)i << ASHIFT) + ABASE为i最后的地址
 *ASHIFT是指tab[i]中第i个元素在相对于数组第一个元素的偏移量，ABASE是数组的偏移地址
 * compareAndSwapObject把tab[i]和c比较，如果相等就tab[i]=v否则tab[i]=c;
*/
/*
利用CAS算法设置i位置上的Node节点。
之所以能实现并发是因为他指定了原来这个节点的值是多少
在CAS算法中，会比较内存中的值与你指定的这个值是否相等，如果相等才接受你的修改，否则拒绝你的修改
*/
static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i,
                                    Node<K,V> c, Node<K,V> v) {
    return U.compareAndSwapObject(tab, ((long)i << ASHIFT) + ABASE, c, v);
}

/*
利用volatile方法设置节点位置的值
这些原子操作保证了ConcurrentHashMap的线程安全。
*/
static final <K,V> void setTabAt(Node<K,V>[] tab, int i, Node<K,V> v) {
    U.putObjectVolatile(tab, ((long)i << ASHIFT) + ABASE, v);
}
```



# put

## 流程

+ 禁止null key/value
+ 根据key高低位参与运算,最终得到非负hash
+ 不断循环,直到插入操作成功
    + 判断是否需要初始化
        + tab == null || (n = tab.length) == 0
        + tab = initTable();
    + 计算位置,且该位置元素为null
        + CAS放入，不需要加锁操作。
        + 利用Unsafe.compareAndSwapObject方法插入Node节点。
        + 如果CAS成功，说明Node节点已经插入，随后addCount(1L, binCount)方法会检查当前容量是否需要进行扩容。
        + 如果CAS失败，说明有其它线程提前插入了节点，自旋重新尝试在这个位置插入节点。
    + hashcode == MOVED ( -1) 
        + tab = helpTransfer(tab, f);
        + 如果f的hash值为-1，说明当前f是ForwardingNode节点，意味有其它线程正在扩容，则一起进行扩容操作。
    + 其余情况把新的Node节点按链表或红黑树的方式插入到合适的位置，这个过程采用同步内置锁实现并发
        + 在节点f上进行同步，节点插入之前，再次利用tabAt(tab, i) == f判断，防止被其它线程修改。
        + 如果f.hash >= 0，说明f是链表结构的头结点，遍历链表，如果找到对应的node节点，则修改value，否则在链表尾部加入节点。
        + 如果f是TreeBin类型节点，说明f是红黑树根节点，则在树结构上遍历元素，更新或增加节点。
        + 如果链表中节点数binCount >= TREEIFY_THRESHOLD(默认是8)，则把链表转化为红黑树结构。
+ addCount(1L，binCount)，主要是看是否需要扩容。当table容量不足的时候，即table的元素数量达到容量阈值sizeCtl，需要对table进行扩容。
    + 构建一个nextTable，大小为table的两倍。
        + 只有单个线程进行nextTable的初始化
        + 通过Unsafe.compareAndSwapInt修改sizeCtl值，保证只有一个线程能够初始化nextTable
        + 扩容后的数组长度为原来的两倍，但是容量是原来的1.5。
    + 把table的数据复制到nextTable中。
        + 可以支持节点的并发复制
        + 大体思想是遍历、复制的过程。
        + 首先根据运算得到需要遍历的次数i，然后利用tabAt方法获得i位置的元素f，初始化一个forwardNode实例fwd。
        + 如果f == null，则在table中的i位置放入fwd，这个过程是采用Unsafe.compareAndSwapObjectf方法实现的，很巧妙的实现了节点的并发移动。
        + 如果f是链表的头节点，就构造一个反序链表，把他们分别放在nextTable的i和i+n的位置上，移动完成，采用Unsafe.putObjectVolatile方法给table原位置赋值fwd。
        + 如果f是TreeBin节点，也做一个反序处理，并判断是否需要untreeify，把处理的结果分别放在nextTable的i和i+n的位置上，移动完成，同样采用Unsafe.putObjectVolatile方法给table原位置赋值fwd。
        + 遍历过所有的节点以后就完成了复制工作，把table指向nextTable，并更新sizeCtl为新数组大小的0.75倍 ，扩容完成。

## 实现

采用CAS+synchronized实现并发插入或更新操作

```java
public V put(K key, V value) {
        return putVal(key, value, false);
    }

final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    
    /*
    //避免hash值是负数
    //HASH_BITS的符号位是0，& 下来的最高位肯定是0
    static final int spread(int h) {
        return (h ^ (h >>> 16)) & HASH_BITS;
    }
    */
    int hash = spread(key.hashCode());
    
    int binCount = 0;
    //这边加了一个循环，就是不断的尝试，因为在table的初始化和casTabAt用到了compareAndSwapInt、compareAndSwapObject
    //因为如果其他线程正在修改tab，那么尝试就会失败，所以这边要加一个for循环，不断的尝试
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
        if (tab == null || (n = tab.length) == 0)
            tab = initTable();
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {//CAS
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))//CAS
                break;                   // no lock when adding to empty bin
        }
        /*
        //如果Table节点是ForwardNode节点的话那么Hash的值就等于-1
        
         static final class ForwardingNode<K,V> extends Node<K,V> {
        final Node<K,V>[] nextTable;
        ForwardingNode(Node<K,V>[] tab) {
            super(MOVED, null, null, null);
            this.nextTable = tab;
        }
        */
        else if ((fh = f.hash) == MOVED)
            //如果线程进入到这边说明已经有其他线程正在做扩容操作，这个是一个辅助方法
            tab = helpTransfer(tab, f);
        else {
            V oldVal = null;
            //这个地方设计非常的巧妙，内置锁synchronized锁住了f,因为f是指定特定的tab[i]的，
            // 所以就锁住了整行链表,这个设计跟分段锁有异曲同工之妙，只是其他读取操作需要用cas来保证
            synchronized (f) {
                if (tabAt(tab, i) == f) {//CAS
                    if (fh >= 0) {
                        binCount = 1;
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            Node<K,V> pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) {//
                        Node<K,V> p;
                        binCount = 2;
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }
            if (binCount != 0) {
                if (binCount >= TREEIFY_THRESHOLD)
                    treeifyBin(tab, i);//转化为红黑树
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    addCount(1L, binCount);
    return null;
}

private final void addCount(long x, int check) {
    CounterCell[] as; long b, s;

    //U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x) 每次竟来都baseCount都加1因为x=1
    /*
    每次都会对baseCount 加1，如果并发竞争太大，那么可能导致U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x) 失败，那么为了提高高并发的时候baseCount可见性失败的问题，又避免一直重试，这样性能会有很大的影响，那么在jdk8的时候是有引入一个类Striped64，其中LongAdder和DoubleAdder就是对这个类的实现。这两个方法都是为解决高并发场景而生的，是AtomicLong的加强版，AtomicLong在高并发场景性能会比LongAdder差。但是LongAdder的空间复杂度会高点。
    */
    if ((as = counterCells) != null ||
        !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {
        CounterCell a; long v; int m;
        boolean uncontended = true;
        if (as == null || (m = as.length - 1) < 0 ||
            (a = as[ThreadLocalRandom.getProbe() & m]) == null ||
            !(uncontended =
              U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {
            //多线程CAS发生失败的时候执行
            fullAddCount(x, uncontended);//2
            return;
        }
        if (check <= 1)
            return;
        s = sumCount();
    }
    if (check >= 0) {
        Node<K,V>[] tab, nt; int n, sc;
        //当条件满足开始扩容
        while (s >= (long)(sc = sizeCtl) && (tab = table) != null &&
               (n = tab.length) < MAXIMUM_CAPACITY) {
            int rs = resizeStamp(n);
            if (sc < 0) {//如果小于0说明已经有线程在进行扩容操作了
                //一下的情况说明已经有在扩容或者多线程进行了扩容，其他线程直接break不要进入扩容操作
                if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                    sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||
                    transferIndex <= 0)
                    break;
                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))//如果相等说明扩容已经完成，可以继续扩容
                    transfer(tab, nt);
            }
            //这个时候sizeCtl已经等于(rs << RESIZE_STAMP_SHIFT) + 2等于一个大的负数，这边加上2很巧妙,因为transfer后面对sizeCtl--操作的时候，最多只能减两次就结束
            else if (U.compareAndSwapInt(this, SIZECTL, sc,
                                         (rs << RESIZE_STAMP_SHIFT) + 2))
                transfer(tab, null);
            s = sumCount();
        }
    }
}

private final void fullAddCount(long x, boolean wasUncontended) {
    int h;
    //获取当前线程的probe值作为hash值,如果0则强制初始化当前线程的Probe值，初始化的probe值不为0
    if ((h = ThreadLocalRandom.getProbe()) == 0) {
        ThreadLocalRandom.localInit();      // force initialization
        h = ThreadLocalRandom.getProbe();
        wasUncontended = true;//设置未竞争标记为true
    }
    boolean collide = false;                // True if last slot nonempty
    for (;;) {
        CounterCell[] as; CounterCell a; int n; long v;
        if ((as = counterCells) != null && (n = as.length) > 0) {
            if ((a = as[(n - 1) & h]) == null) {
                if (cellsBusy == 0) {            // Try to attach new Cell如果当前没有CounterCell就创建一个
                    CounterCell r = new CounterCell(x); // Optimistic create
                    if (cellsBusy == 0 &&
                        U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {//这边加上cellsBusy锁
                        boolean created = false;
                        try {               // Recheck under lock
                            CounterCell[] rs; int m, j;
                            if ((rs = counterCells) != null &&
                                (m = rs.length) > 0 &&
                                rs[j = (m - 1) & h] == null) {
                                rs[j] = r;
                                created = true;
                            }
                        } finally {
                            cellsBusy = 0;//释放cellsBusy锁，让其他线程可以进来
                        }
                        if (created)
                            break;
                        continue;           // Slot is now non-empty
                    }
                }
                collide = false;
            }
            else if (!wasUncontended)       // CAS already known to fail wasUncontended为false说明已经发生了竞争，重置为true重新执行上面代码
                wasUncontended = true;      // Continue after rehash
            else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))//对cell的value值进行累计x（1）
                break;
            else if (counterCells != as || n >= NCPU)
                collide = false;            // At max size or stale 表明as已经过时，说明cells已经初始化完成，看下面，重置collide为false表明已经存在竞争
            else if (!collide)
                collide = true;
            else if (cellsBusy == 0 &&
                     U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
                try {
                    if (counterCells == as) {// Expand table unless stale 下面的代码主要是给counterCells扩容，尽可能避免冲突
                        CounterCell[] rs = new CounterCell[n << 1];
                        for (int i = 0; i < n; ++i)
                            rs[i] = as[i];
                        counterCells = rs;
                    }
                } finally {
                    cellsBusy = 0;
                }
                collide = false;
                continue;                   // Retry with expanded table
            }
            h = ThreadLocalRandom.advanceProbe(h);
        }
        else if (cellsBusy == 0 && counterCells == as &&
                 U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {//表明counterCells还没初始化，则初始化，这边用cellsBusy加锁
            boolean init = false;
            try {                           // Initialize table
                if (counterCells == as) {
                    CounterCell[] rs = new CounterCell[2];
                    rs[h & 1] = new CounterCell(x);
                    counterCells = rs;
                    init = true;
                }
            } finally {
                cellsBusy = 0;
            }
            if (init)
                break;
        }
        else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x))//最终如果上面的都失败就把x累计到baseCount
            break;                          // Fall back on using base
    }
}
```

# get

+ 判断table是否为空，如果为空，直接返回null。
+ 计算key的hash值，并获取指定table中指定位置的Node节点，通过遍历链表或则树结构找到对应的节点，返回value值。

需要cas来保证变量的原子性。如果tab[i]正被锁住，那么CAS就会失败，失败之后就会不断的重试。这也保证了get在高并发情况下不会出错。

有多少种情况会导致get在并发的情况下可能取不到值。1、一个线程在get的时候，另一个线程在对同一个key的node进行remove操作；2、一个线程在get的时候，另一个线程正则重排table。可能导致旧table取不到值。
那么本质是，我在get的时候，有其他线程在对同一桶的链表或树进行修改。那么get是怎么保证同步性的呢？我们看到e = tabAt(tab, (n - 1) & h)) != null

它是对tab[i]进行原子性的读取，因为我们知道putVal等对table的桶操作是有加锁的，那么一般情况下我们对桶的读也是要加锁的，但是我们这边为什么不需要加锁呢？因为我们用了Unsafe的getObjectVolatile，因为table是volatile类型，所以对tab[i]的原子请求也是可见的。因为如果同步正确的情况下，根据happens-before原则，**对volatile域的写入操作happens-before于每一个后续对同一域的读操作**。所以不管其他线程对table链表或树的修改，都对get读取可见。

```java
public V get(Object key) {
    Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
    int h = spread(key.hashCode());
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (e = tabAt(tab, (n - 1) & h)) != null) {
        if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                return e.val;
        }
        else if (eh < 0)//如果eh=-1就说明e节点为ForWordingNode,这说明什么，说明这个节点已经不存在了，被另一个线程正则扩容
        //所以要查找key对应的值的话，直接到新newtable找
            return (p = e.find(h, key)) != null ? p.val : null;
        while ((e = e.next) != null) {
            if (e.hash == h &&
                ((ek = e.key) == key || (ek != null && key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
```

# 初始化方法initTable

+ 调用它的构造方法仅仅是设置了一些参数而已。
+ 整个table的初始化是在向ConcurrentHashMap中插入元素的时候发生的。
+ 如调用put、computeIfAbsent、compute、merge等方法的时候，调用时机是检查table==null。
+ 初始化方法主要应用了关键属性sizeCtl
    + 如果一个线程发现sizeCtl<0，意味着另外的线程执行CAS操作成功，当前线程只需要让出cpu时间片，初始化只能由一个线程完成，Thread.yield();
    + 如果获得了初始化权限，就用CAS方法将sizeCtl置为-1，防止其他线程进入。U.compareAndSwapInt(this, SIZECTL, sc, -1)
    + 初始化数组后，将sizeCtl的值改为0.75*n

# 扩容方法 transfer

+ 支持多线程进行扩容操作，而且没有加锁。
+ 第一部分是构建一个nextTable,它的容量是原来的两倍，这个操作是单线程完成的。这个单线程的保证是通过RESIZE_STAMP_SHIFT这个常量经过一次运算来保证的
+ 第二个部分就是将原来table中的元素复制到nextTable中，允许多线程进行操作。如果遍历到的节点是forward节点，就向后继续遍历，再加上给节点上锁的机制，就完成了多线程的控制。多线程遍历节点，处理了一个节点，就把对应点的值set为forward，另一个线程看到forward，就向后遍历。这样交叉就完成了复制工作。

# helpTransfer方法

+ 协助扩容的方法
+ 这个方法被调用的时候，当前ConcurrentHashMap一定已经有了nextTable对象，首先拿到这个nextTable对象，调用transfer方法。
+ 回看上面的transfer方法可以看到，当本线程进入扩容方法的时候会直接进入复制阶段。

# treeifyBin方法

+ 这个方法用于将过长的链表转换为TreeBin对象。但是他并不是直接转换，而是进行一次容量判断，如果容量没有达到转换的要求，直接进行扩容操作并返回；
+ 如果满足条件才链表的结构抓换为TreeBin ，这与HashMap不同的是，它并没有把TreeNode直接放入红黑树，而是利用了TreeBin这个小容器来封装所有的TreeNode.

# Size

+ 对于ConcurrentHashMap来说，这个table里到底装了多少东西其实是个不确定的数量，因为不可能在调用size()方法的时候像GC的“stop the world”一样让其他线程都停下来让你去统计，因此只能说这个数量是个估计值。